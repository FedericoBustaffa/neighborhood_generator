{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4bb941d1-38d5-46ff-8a9b-1c8fac8f0136",
   "metadata": {},
   "source": [
    "# Analisi risultati\n",
    "\n",
    "Nel notebook vengono svolte alcune analisi sul dataset generato tramite varie\n",
    "simulazioni su diversi dataset e utilizzando tre diversi classificatori. In\n",
    "particolare sono stati usati una **SVM**, un **MultiLayer Perceptron** e un\n",
    "**Random Forest**. Non sono stati effettuati benchmark sulle prestazioni, si\n",
    "sta infatti considerando solo la qualit√† dei risultati ottenuti.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "925e79e6-f66e-4a19-beb5-f0512e49d253",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset_id</th>\n",
       "      <th>samples</th>\n",
       "      <th>features</th>\n",
       "      <th>classes</th>\n",
       "      <th>clusters</th>\n",
       "      <th>point</th>\n",
       "      <th>class</th>\n",
       "      <th>target</th>\n",
       "      <th>model</th>\n",
       "      <th>min_fitness</th>\n",
       "      <th>mean_fitness</th>\n",
       "      <th>max_fitness</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>SVC</td>\n",
       "      <td>-0.856705</td>\n",
       "      <td>-0.689994</td>\n",
       "      <td>-0.530150</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>SVC</td>\n",
       "      <td>-0.208582</td>\n",
       "      <td>-0.110090</td>\n",
       "      <td>-0.002880</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>SVC</td>\n",
       "      <td>-0.114668</td>\n",
       "      <td>-0.056235</td>\n",
       "      <td>-0.000577</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>SVC</td>\n",
       "      <td>-0.582123</td>\n",
       "      <td>-0.517654</td>\n",
       "      <td>-0.473684</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>SVC</td>\n",
       "      <td>-1.055623</td>\n",
       "      <td>-1.001681</td>\n",
       "      <td>-0.954841</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>SVC</td>\n",
       "      <td>-0.176636</td>\n",
       "      <td>-0.095448</td>\n",
       "      <td>-0.000167</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>SVC</td>\n",
       "      <td>-0.911452</td>\n",
       "      <td>-0.834307</td>\n",
       "      <td>-0.760698</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>SVC</td>\n",
       "      <td>-0.181263</td>\n",
       "      <td>-0.095799</td>\n",
       "      <td>-0.000345</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>SVC</td>\n",
       "      <td>-0.224299</td>\n",
       "      <td>-0.121575</td>\n",
       "      <td>-0.000027</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>SVC</td>\n",
       "      <td>-1.394745</td>\n",
       "      <td>-1.349189</td>\n",
       "      <td>-1.314164</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>-0.795648</td>\n",
       "      <td>-0.610948</td>\n",
       "      <td>-0.449269</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>-0.205658</td>\n",
       "      <td>-0.110161</td>\n",
       "      <td>-0.001897</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>-0.127417</td>\n",
       "      <td>-0.063036</td>\n",
       "      <td>-0.000577</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>-0.598422</td>\n",
       "      <td>-0.530928</td>\n",
       "      <td>-0.479891</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>-1.047814</td>\n",
       "      <td>-0.989773</td>\n",
       "      <td>-0.944066</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>-0.186712</td>\n",
       "      <td>-0.101195</td>\n",
       "      <td>-0.000167</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>-0.881342</td>\n",
       "      <td>-0.804950</td>\n",
       "      <td>-0.745488</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>-0.169235</td>\n",
       "      <td>-0.088741</td>\n",
       "      <td>-0.000479</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>-0.217108</td>\n",
       "      <td>-0.114410</td>\n",
       "      <td>-0.000027</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>-1.408336</td>\n",
       "      <td>-1.365962</td>\n",
       "      <td>-1.329961</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>SVC</td>\n",
       "      <td>-1.065257</td>\n",
       "      <td>-0.944008</td>\n",
       "      <td>-0.841080</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>SVC</td>\n",
       "      <td>-0.213352</td>\n",
       "      <td>-0.113696</td>\n",
       "      <td>-0.002871</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>SVC</td>\n",
       "      <td>-2.083704</td>\n",
       "      <td>-1.854849</td>\n",
       "      <td>-1.604303</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>SVC</td>\n",
       "      <td>-0.821988</td>\n",
       "      <td>-0.479632</td>\n",
       "      <td>-0.002241</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>SVC</td>\n",
       "      <td>-0.225731</td>\n",
       "      <td>-0.120416</td>\n",
       "      <td>-0.002665</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>SVC</td>\n",
       "      <td>-0.863426</td>\n",
       "      <td>-0.726676</td>\n",
       "      <td>-0.595085</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>SVC</td>\n",
       "      <td>-0.220015</td>\n",
       "      <td>-0.113738</td>\n",
       "      <td>-0.002030</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>SVC</td>\n",
       "      <td>-0.569830</td>\n",
       "      <td>-0.406842</td>\n",
       "      <td>-0.291370</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>SVC</td>\n",
       "      <td>-0.291381</td>\n",
       "      <td>-0.150626</td>\n",
       "      <td>-0.000913</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>SVC</td>\n",
       "      <td>-0.735338</td>\n",
       "      <td>-0.562928</td>\n",
       "      <td>-0.383636</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>-0.975691</td>\n",
       "      <td>-0.872044</td>\n",
       "      <td>-0.783924</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>-0.200522</td>\n",
       "      <td>-0.106938</td>\n",
       "      <td>-0.002871</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>-2.041589</td>\n",
       "      <td>-1.793544</td>\n",
       "      <td>-1.500296</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>-0.786443</td>\n",
       "      <td>-0.452637</td>\n",
       "      <td>-0.002983</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>-0.240539</td>\n",
       "      <td>-0.128429</td>\n",
       "      <td>-0.002665</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>-0.932369</td>\n",
       "      <td>-0.815941</td>\n",
       "      <td>-0.692181</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>-0.220562</td>\n",
       "      <td>-0.113096</td>\n",
       "      <td>-0.002030</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>-0.618812</td>\n",
       "      <td>-0.488922</td>\n",
       "      <td>-0.389487</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>-0.305697</td>\n",
       "      <td>-0.155739</td>\n",
       "      <td>-0.000913</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>-0.706210</td>\n",
       "      <td>-0.491541</td>\n",
       "      <td>-0.264315</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    dataset_id  samples  features  classes  clusters  point  class  target  \\\n",
       "0            0      100         2        2         1      0      1       0   \n",
       "1            0      100         2        2         1      0      1       1   \n",
       "2            0      100         2        2         1      1      0       0   \n",
       "3            0      100         2        2         1      1      0       1   \n",
       "4            0      100         2        2         1      2      1       0   \n",
       "5            0      100         2        2         1      2      1       1   \n",
       "6            0      100         2        2         1      3      1       0   \n",
       "7            0      100         2        2         1      3      1       1   \n",
       "8            0      100         2        2         1      4      0       0   \n",
       "9            0      100         2        2         1      4      0       1   \n",
       "10           0      100         2        2         1      0      1       0   \n",
       "11           0      100         2        2         1      0      1       1   \n",
       "12           0      100         2        2         1      1      0       0   \n",
       "13           0      100         2        2         1      1      0       1   \n",
       "14           0      100         2        2         1      2      1       0   \n",
       "15           0      100         2        2         1      2      1       1   \n",
       "16           0      100         2        2         1      3      1       0   \n",
       "17           0      100         2        2         1      3      1       1   \n",
       "18           0      100         2        2         1      4      0       0   \n",
       "19           0      100         2        2         1      4      0       1   \n",
       "20           1      100         2        2         2      0      1       0   \n",
       "21           1      100         2        2         2      0      1       1   \n",
       "22           1      100         2        2         2      1      1       0   \n",
       "23           1      100         2        2         2      1      1       1   \n",
       "24           1      100         2        2         2      2      0       0   \n",
       "25           1      100         2        2         2      2      0       1   \n",
       "26           1      100         2        2         2      3      0       0   \n",
       "27           1      100         2        2         2      3      0       1   \n",
       "28           1      100         2        2         2      4      0       0   \n",
       "29           1      100         2        2         2      4      0       1   \n",
       "30           1      100         2        2         2      0      1       0   \n",
       "31           1      100         2        2         2      0      1       1   \n",
       "32           1      100         2        2         2      1      1       0   \n",
       "33           1      100         2        2         2      1      1       1   \n",
       "34           1      100         2        2         2      2      0       0   \n",
       "35           1      100         2        2         2      2      0       1   \n",
       "36           1      100         2        2         2      3      0       0   \n",
       "37           1      100         2        2         2      3      0       1   \n",
       "38           1      100         2        2         2      4      0       0   \n",
       "39           1      100         2        2         2      4      0       1   \n",
       "\n",
       "            model  min_fitness  mean_fitness  max_fitness  accuracy  \n",
       "0             SVC    -0.856705     -0.689994    -0.530150       1.0  \n",
       "1             SVC    -0.208582     -0.110090    -0.002880       1.0  \n",
       "2             SVC    -0.114668     -0.056235    -0.000577       1.0  \n",
       "3             SVC    -0.582123     -0.517654    -0.473684       1.0  \n",
       "4             SVC    -1.055623     -1.001681    -0.954841       1.0  \n",
       "5             SVC    -0.176636     -0.095448    -0.000167       1.0  \n",
       "6             SVC    -0.911452     -0.834307    -0.760698       1.0  \n",
       "7             SVC    -0.181263     -0.095799    -0.000345       1.0  \n",
       "8             SVC    -0.224299     -0.121575    -0.000027       1.0  \n",
       "9             SVC    -1.394745     -1.349189    -1.314164       1.0  \n",
       "10  MLPClassifier    -0.795648     -0.610948    -0.449269       1.0  \n",
       "11  MLPClassifier    -0.205658     -0.110161    -0.001897       1.0  \n",
       "12  MLPClassifier    -0.127417     -0.063036    -0.000577       1.0  \n",
       "13  MLPClassifier    -0.598422     -0.530928    -0.479891       1.0  \n",
       "14  MLPClassifier    -1.047814     -0.989773    -0.944066       1.0  \n",
       "15  MLPClassifier    -0.186712     -0.101195    -0.000167       1.0  \n",
       "16  MLPClassifier    -0.881342     -0.804950    -0.745488       1.0  \n",
       "17  MLPClassifier    -0.169235     -0.088741    -0.000479       1.0  \n",
       "18  MLPClassifier    -0.217108     -0.114410    -0.000027       1.0  \n",
       "19  MLPClassifier    -1.408336     -1.365962    -1.329961       1.0  \n",
       "20            SVC    -1.065257     -0.944008    -0.841080       1.0  \n",
       "21            SVC    -0.213352     -0.113696    -0.002871       1.0  \n",
       "22            SVC    -2.083704     -1.854849    -1.604303       1.0  \n",
       "23            SVC    -0.821988     -0.479632    -0.002241       1.0  \n",
       "24            SVC    -0.225731     -0.120416    -0.002665       1.0  \n",
       "25            SVC    -0.863426     -0.726676    -0.595085       1.0  \n",
       "26            SVC    -0.220015     -0.113738    -0.002030       1.0  \n",
       "27            SVC    -0.569830     -0.406842    -0.291370       1.0  \n",
       "28            SVC    -0.291381     -0.150626    -0.000913       1.0  \n",
       "29            SVC    -0.735338     -0.562928    -0.383636       1.0  \n",
       "30  MLPClassifier    -0.975691     -0.872044    -0.783924       1.0  \n",
       "31  MLPClassifier    -0.200522     -0.106938    -0.002871       1.0  \n",
       "32  MLPClassifier    -2.041589     -1.793544    -1.500296       1.0  \n",
       "33  MLPClassifier    -0.786443     -0.452637    -0.002983       1.0  \n",
       "34  MLPClassifier    -0.240539     -0.128429    -0.002665       1.0  \n",
       "35  MLPClassifier    -0.932369     -0.815941    -0.692181       1.0  \n",
       "36  MLPClassifier    -0.220562     -0.113096    -0.002030       1.0  \n",
       "37  MLPClassifier    -0.618812     -0.488922    -0.389487       1.0  \n",
       "38  MLPClassifier    -0.305697     -0.155739    -0.000913       1.0  \n",
       "39  MLPClassifier    -0.706210     -0.491541    -0.264315       1.0  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"../datasets/test.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8b71326-91bc-45ed-88d1-bb28ae55cf95",
   "metadata": {},
   "source": [
    "Ogni riga del dataset contiene quindi:\n",
    "\n",
    "- **dataset_id**: ID univoco per ogni dataset analizzato.\n",
    "- **point**: ogni punto del dataset viene semplicemente enumerato da $0$ a\n",
    "  $N-1$, dove $N$ √® il numero totale di punti del dataset.\n",
    "- **class**: classe del punto.\n",
    "- **target**: classe target dell'algoritmo genetico.\n",
    "- **model**: il modello classificatore utilizzato.\n",
    "- **min/mean/max_fitness**: valore minimo, medio e massimo di fitness estratti\n",
    "  dalla hall of fame prodotta ad ogni esecuzione dell'algoritmo genetico.\n",
    "- **accuracy**: calcolata come numero di individui nella hall of fame\n",
    "  classificati nella classe target diviso numero di individui totali presenti\n",
    "  nella hall of fame.\n",
    "\n",
    "Possiamo quindi vedere ogni riga come una singola esecuzione dell'algoritmo\n",
    "genetico su uno specifico punto e su una specifica classe target.\n",
    "\n",
    "Dato che i valori di fitness non sono altro che la distanza di ogni punto\n",
    "sintetico dal punto preso in esame, moltiplicata per $-1$. Possiamo quindi\n",
    "convertire le tre colonne di fitness in valori di distanza rimoltiplicandole\n",
    "per $-1$ di modo da avere valori meglio interpretabili.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8291176a-82b4-4fa2-b89a-9aec43f4e457",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset_id</th>\n",
       "      <th>samples</th>\n",
       "      <th>features</th>\n",
       "      <th>classes</th>\n",
       "      <th>clusters</th>\n",
       "      <th>point</th>\n",
       "      <th>class</th>\n",
       "      <th>target</th>\n",
       "      <th>model</th>\n",
       "      <th>min_fitness</th>\n",
       "      <th>mean_fitness</th>\n",
       "      <th>max_fitness</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>SVC</td>\n",
       "      <td>0.856705</td>\n",
       "      <td>0.689994</td>\n",
       "      <td>0.530150</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>SVC</td>\n",
       "      <td>0.208582</td>\n",
       "      <td>0.110090</td>\n",
       "      <td>0.002880</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>SVC</td>\n",
       "      <td>0.114668</td>\n",
       "      <td>0.056235</td>\n",
       "      <td>0.000577</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>SVC</td>\n",
       "      <td>0.582123</td>\n",
       "      <td>0.517654</td>\n",
       "      <td>0.473684</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>SVC</td>\n",
       "      <td>1.055623</td>\n",
       "      <td>1.001681</td>\n",
       "      <td>0.954841</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>SVC</td>\n",
       "      <td>0.176636</td>\n",
       "      <td>0.095448</td>\n",
       "      <td>0.000167</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>SVC</td>\n",
       "      <td>0.911452</td>\n",
       "      <td>0.834307</td>\n",
       "      <td>0.760698</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>SVC</td>\n",
       "      <td>0.181263</td>\n",
       "      <td>0.095799</td>\n",
       "      <td>0.000345</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>SVC</td>\n",
       "      <td>0.224299</td>\n",
       "      <td>0.121575</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>SVC</td>\n",
       "      <td>1.394745</td>\n",
       "      <td>1.349189</td>\n",
       "      <td>1.314164</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>0.795648</td>\n",
       "      <td>0.610948</td>\n",
       "      <td>0.449269</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>0.205658</td>\n",
       "      <td>0.110161</td>\n",
       "      <td>0.001897</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>0.127417</td>\n",
       "      <td>0.063036</td>\n",
       "      <td>0.000577</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>0.598422</td>\n",
       "      <td>0.530928</td>\n",
       "      <td>0.479891</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>1.047814</td>\n",
       "      <td>0.989773</td>\n",
       "      <td>0.944066</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>0.186712</td>\n",
       "      <td>0.101195</td>\n",
       "      <td>0.000167</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>0.881342</td>\n",
       "      <td>0.804950</td>\n",
       "      <td>0.745488</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>0.169235</td>\n",
       "      <td>0.088741</td>\n",
       "      <td>0.000479</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>0.217108</td>\n",
       "      <td>0.114410</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>1.408336</td>\n",
       "      <td>1.365962</td>\n",
       "      <td>1.329961</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>SVC</td>\n",
       "      <td>1.065257</td>\n",
       "      <td>0.944008</td>\n",
       "      <td>0.841080</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>SVC</td>\n",
       "      <td>0.213352</td>\n",
       "      <td>0.113696</td>\n",
       "      <td>0.002871</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>SVC</td>\n",
       "      <td>2.083704</td>\n",
       "      <td>1.854849</td>\n",
       "      <td>1.604303</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>SVC</td>\n",
       "      <td>0.821988</td>\n",
       "      <td>0.479632</td>\n",
       "      <td>0.002241</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>SVC</td>\n",
       "      <td>0.225731</td>\n",
       "      <td>0.120416</td>\n",
       "      <td>0.002665</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>SVC</td>\n",
       "      <td>0.863426</td>\n",
       "      <td>0.726676</td>\n",
       "      <td>0.595085</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>SVC</td>\n",
       "      <td>0.220015</td>\n",
       "      <td>0.113738</td>\n",
       "      <td>0.002030</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>SVC</td>\n",
       "      <td>0.569830</td>\n",
       "      <td>0.406842</td>\n",
       "      <td>0.291370</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>SVC</td>\n",
       "      <td>0.291381</td>\n",
       "      <td>0.150626</td>\n",
       "      <td>0.000913</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>SVC</td>\n",
       "      <td>0.735338</td>\n",
       "      <td>0.562928</td>\n",
       "      <td>0.383636</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>0.975691</td>\n",
       "      <td>0.872044</td>\n",
       "      <td>0.783924</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>0.200522</td>\n",
       "      <td>0.106938</td>\n",
       "      <td>0.002871</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>2.041589</td>\n",
       "      <td>1.793544</td>\n",
       "      <td>1.500296</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>0.786443</td>\n",
       "      <td>0.452637</td>\n",
       "      <td>0.002983</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>0.240539</td>\n",
       "      <td>0.128429</td>\n",
       "      <td>0.002665</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>0.932369</td>\n",
       "      <td>0.815941</td>\n",
       "      <td>0.692181</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>0.220562</td>\n",
       "      <td>0.113096</td>\n",
       "      <td>0.002030</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>0.618812</td>\n",
       "      <td>0.488922</td>\n",
       "      <td>0.389487</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>0.305697</td>\n",
       "      <td>0.155739</td>\n",
       "      <td>0.000913</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>0.706210</td>\n",
       "      <td>0.491541</td>\n",
       "      <td>0.264315</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    dataset_id  samples  features  classes  clusters  point  class  target  \\\n",
       "0            0      100         2        2         1      0      1       0   \n",
       "1            0      100         2        2         1      0      1       1   \n",
       "2            0      100         2        2         1      1      0       0   \n",
       "3            0      100         2        2         1      1      0       1   \n",
       "4            0      100         2        2         1      2      1       0   \n",
       "5            0      100         2        2         1      2      1       1   \n",
       "6            0      100         2        2         1      3      1       0   \n",
       "7            0      100         2        2         1      3      1       1   \n",
       "8            0      100         2        2         1      4      0       0   \n",
       "9            0      100         2        2         1      4      0       1   \n",
       "10           0      100         2        2         1      0      1       0   \n",
       "11           0      100         2        2         1      0      1       1   \n",
       "12           0      100         2        2         1      1      0       0   \n",
       "13           0      100         2        2         1      1      0       1   \n",
       "14           0      100         2        2         1      2      1       0   \n",
       "15           0      100         2        2         1      2      1       1   \n",
       "16           0      100         2        2         1      3      1       0   \n",
       "17           0      100         2        2         1      3      1       1   \n",
       "18           0      100         2        2         1      4      0       0   \n",
       "19           0      100         2        2         1      4      0       1   \n",
       "20           1      100         2        2         2      0      1       0   \n",
       "21           1      100         2        2         2      0      1       1   \n",
       "22           1      100         2        2         2      1      1       0   \n",
       "23           1      100         2        2         2      1      1       1   \n",
       "24           1      100         2        2         2      2      0       0   \n",
       "25           1      100         2        2         2      2      0       1   \n",
       "26           1      100         2        2         2      3      0       0   \n",
       "27           1      100         2        2         2      3      0       1   \n",
       "28           1      100         2        2         2      4      0       0   \n",
       "29           1      100         2        2         2      4      0       1   \n",
       "30           1      100         2        2         2      0      1       0   \n",
       "31           1      100         2        2         2      0      1       1   \n",
       "32           1      100         2        2         2      1      1       0   \n",
       "33           1      100         2        2         2      1      1       1   \n",
       "34           1      100         2        2         2      2      0       0   \n",
       "35           1      100         2        2         2      2      0       1   \n",
       "36           1      100         2        2         2      3      0       0   \n",
       "37           1      100         2        2         2      3      0       1   \n",
       "38           1      100         2        2         2      4      0       0   \n",
       "39           1      100         2        2         2      4      0       1   \n",
       "\n",
       "            model  min_fitness  mean_fitness  max_fitness  accuracy  \n",
       "0             SVC     0.856705      0.689994     0.530150       1.0  \n",
       "1             SVC     0.208582      0.110090     0.002880       1.0  \n",
       "2             SVC     0.114668      0.056235     0.000577       1.0  \n",
       "3             SVC     0.582123      0.517654     0.473684       1.0  \n",
       "4             SVC     1.055623      1.001681     0.954841       1.0  \n",
       "5             SVC     0.176636      0.095448     0.000167       1.0  \n",
       "6             SVC     0.911452      0.834307     0.760698       1.0  \n",
       "7             SVC     0.181263      0.095799     0.000345       1.0  \n",
       "8             SVC     0.224299      0.121575     0.000027       1.0  \n",
       "9             SVC     1.394745      1.349189     1.314164       1.0  \n",
       "10  MLPClassifier     0.795648      0.610948     0.449269       1.0  \n",
       "11  MLPClassifier     0.205658      0.110161     0.001897       1.0  \n",
       "12  MLPClassifier     0.127417      0.063036     0.000577       1.0  \n",
       "13  MLPClassifier     0.598422      0.530928     0.479891       1.0  \n",
       "14  MLPClassifier     1.047814      0.989773     0.944066       1.0  \n",
       "15  MLPClassifier     0.186712      0.101195     0.000167       1.0  \n",
       "16  MLPClassifier     0.881342      0.804950     0.745488       1.0  \n",
       "17  MLPClassifier     0.169235      0.088741     0.000479       1.0  \n",
       "18  MLPClassifier     0.217108      0.114410     0.000027       1.0  \n",
       "19  MLPClassifier     1.408336      1.365962     1.329961       1.0  \n",
       "20            SVC     1.065257      0.944008     0.841080       1.0  \n",
       "21            SVC     0.213352      0.113696     0.002871       1.0  \n",
       "22            SVC     2.083704      1.854849     1.604303       1.0  \n",
       "23            SVC     0.821988      0.479632     0.002241       1.0  \n",
       "24            SVC     0.225731      0.120416     0.002665       1.0  \n",
       "25            SVC     0.863426      0.726676     0.595085       1.0  \n",
       "26            SVC     0.220015      0.113738     0.002030       1.0  \n",
       "27            SVC     0.569830      0.406842     0.291370       1.0  \n",
       "28            SVC     0.291381      0.150626     0.000913       1.0  \n",
       "29            SVC     0.735338      0.562928     0.383636       1.0  \n",
       "30  MLPClassifier     0.975691      0.872044     0.783924       1.0  \n",
       "31  MLPClassifier     0.200522      0.106938     0.002871       1.0  \n",
       "32  MLPClassifier     2.041589      1.793544     1.500296       1.0  \n",
       "33  MLPClassifier     0.786443      0.452637     0.002983       1.0  \n",
       "34  MLPClassifier     0.240539      0.128429     0.002665       1.0  \n",
       "35  MLPClassifier     0.932369      0.815941     0.692181       1.0  \n",
       "36  MLPClassifier     0.220562      0.113096     0.002030       1.0  \n",
       "37  MLPClassifier     0.618812      0.488922     0.389487       1.0  \n",
       "38  MLPClassifier     0.305697      0.155739     0.000913       1.0  \n",
       "39  MLPClassifier     0.706210      0.491541     0.264315       1.0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[[\"min_fitness\", \"mean_fitness\", \"max_fitness\"]] *= -1.0\n",
    "df.columns # change also columns name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cdda0d5-0ba4-491d-9cfd-47dd763ac064",
   "metadata": {},
   "source": [
    "## Precisione\n",
    "\n",
    "Come prima analisi possiamo andare a vedere i risultati ottenuti da ogni\n",
    "modello, per ogni dataset in termini di accuracy.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4268e792-246c-4d87-8fb9-be2145aed119",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset_id</th>\n",
       "      <th>model</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>SVC</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>SVC</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   dataset_id          model  mean  std\n",
       "0           0  MLPClassifier   1.0  0.0\n",
       "1           0            SVC   1.0  0.0\n",
       "2           1  MLPClassifier   1.0  0.0\n",
       "3           1            SVC   1.0  0.0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby([\"dataset_id\", \"model\"]).agg([\"mean\", \"std\"])[\"accuracy\"].reset_index()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03d675d9-c112-485c-89cf-109d5f2ccf97",
   "metadata": {},
   "source": [
    "Come possiamo notare abbiamo una media di $1.0$ e una deviazione standard\n",
    "di $0.0$ come sperato. Deduciamo quindi che l'algoritmo genetico abbia prodotto\n",
    "la popolazione sintetica finale sperata.\n",
    "\n",
    "## Fitness\n",
    "\n",
    "Vediamo ora se ci sono differenze signi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f838f007-4b8b-482c-b6fe-5f5580848e51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset_id</th>\n",
       "      <th>model</th>\n",
       "      <th>mean_fitness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>-0.478011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>SVC</td>\n",
       "      <td>-0.487197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>-0.541883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>SVC</td>\n",
       "      <td>-0.547341</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   dataset_id          model  mean_fitness\n",
       "0           0  MLPClassifier     -0.478011\n",
       "1           0            SVC     -0.487197\n",
       "2           1  MLPClassifier     -0.541883\n",
       "3           1            SVC     -0.547341"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_fitness = df.groupby([\"dataset_id\", \"model\"]).mean()[\"mean_fitness\"].reset_index()\n",
    "mean_fitness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3b6bbdd2-ee62-4c88-978f-eb253a739eb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABR8AAAL0CAYAAACF5UATAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/GU6VOAAAACXBIWXMAAA9hAAAPYQGoP6dpAABBr0lEQVR4nO3de5SWdb3//9cMMBwcDhrGqI2Nx5RUIAkFt/pNMWxb21NJZYFI7NTcamQmtgVL22ApkUZR9gXcaYGWaTvTDhSeywJPXw/tPAAeOKgpCPxkkJnfHy2nJtAYnQ/jDI/HWvdaM5/7OrxvYrkWz67rvioaGxsbAwAAAADQyirbegAAAAAAoGMSHwEAAACAIsRHAAAAAKAI8REAAAAAKEJ8BAAAAACKEB8BAAAAgCLERwAAAACgCPERAAAAACiic1sPsKU1NDTkmWeeSc+ePVNRUdHW4wAAAABAu9LY2JiXXnopO+64YyorX//axq0uPj7zzDOpra1t6zEAAAAAoF178skn8453vON1t9nq4mPPnj2T/PUPp1evXm08DQAAAAC0L6tWrUptbW1TZ3s9W118fPVW6169eomPAAAAAPAGbc5XGnrgDAAAAABQhPgIAAAAABQhPgIAAAAARWx13/m4ORobG/PKK69kw4YNbT0Kb3GdOnVK586dN+s7DgAAAAC2NuLjP6ivr8/SpUuzdu3ath6FdqJHjx7ZYYcdUlVV1dajAAAAALyliI9/p6GhIU888UQ6deqUHXfcMVVVVa5o4zU1Njamvr4+zz77bJ544onsscceqaz0TQYAAAAArxIf/059fX0aGhpSW1ubHj16tPU4tAPdu3dPly5dsnjx4tTX16dbt25tPRIAAADAW4bLtDbB1Wu0hL8vAAAAAJummgAAAAAARYiPAAAAAEARvvNxM9Wde+MWPd+iKUdt0fMBAAAAQGtz5WMH8uyzz+bUU0/NzjvvnK5du6ampiYjRozILbfckr59+2bKlCmb3O/CCy9Mv379sn79+iR/ffDOV7/61QwYMCA9evRI3759c9BBB2XWrFlN2wAAAADAP+PKxw7k+OOPT319fa688srsuuuuWb58eebNm5eVK1fmE5/4RGbNmpVzzz232T6NjY2ZPXt2Ro0alS5duqS+vj4jRozIfffdlwsvvDAHHXRQevXqld/97ne55JJLMmjQoAwcOLBtPiAAAAAA7Yr42EG8+OKLue222zJ//vwceuihSZJ3vvOdGTJkSJJkl112yTe+8Y3cfvvt+Zd/+Zem/W655ZY8/vjjGTt2bJJk2rRpufXWW/PHP/4xgwYNatpu1113zUc+8pHU19dvwU8FAAAAQHvmtusOorq6OtXV1bn++uuzbt26jd7fd9998973vjczZ85stj5r1qwMGzYse+21V5Lk6quvzvDhw5uFx1d16dIl22yzTZkPAAAAAECHIz52EJ07d87s2bNz5ZVXpk+fPjnooINy3nnn5f7772/aZuzYsbn22muzevXqJMlLL72UH/3oRzn55JObtvnzn//cFCIBAAAA4M0QHzuQ448/Ps8880x++tOf5sgjj8z8+fPznve8J7Nnz06SfOxjH8uGDRtyzTXXJEnmzp2bysrKjBw5sukYjY2NbTE6AAAAAB2Q+NjBdOvWLUcccUTOP//83HnnnTnppJMyadKkJEmvXr3y4Q9/OLNmzUry11uuTzjhhFRXVzftv+eee+aRRx5pk9kBAAAA6FjExw6uf//+WbNmTdPvY8eOze23356f/exnufPOO5seNPOqj3/84/n1r3+de+65Z6NjrV+/vtmxAAAAAOD1iI8dxPPPP5/DDjssV111Ve6///488cQTufbaa/PVr341Rx99dNN2hxxySHbfffeMGjUqe+21V4YNG9bsOGeddVYOOuigHH744Zk+fXruu+++PP7447nmmmty4IEH5s9//vOW/mgAAAAAtFOd23qA9mLRlKPaeoTXVV1dnQMOOCBf//rX89hjj2X9+vWpra3NuHHjct555zVtV1FRkZNPPjnnnXdeJkyYsNFxunbtml/96lf5+te/nu985zs5++yz06NHj+y9994544wzss8++2zJjwUAAABAO1bRuJU9YWTVqlXp3bt3Vq5cmV69ejV77+WXX84TTzyRXXbZJd26dWujCWlv/L0BAAAAtiav19f+kduuAQAAAIAixEcAAAAAoAjxEQAAAAAoQnwEAAAAAIoQHwEAAACAIsRHAAAAAKAI8REAAAAAKEJ8BAAAAACK6NzWA9Bx1dXV5ayzzspZZ51V9DyLFi3KLrvsknvuuScDBw5Mktxxxx055ZRT8sgjj+Soo47KWWedlfe973154YUX0qdPn6LzAAAAW5+6c29s6xF4C1g05ai2HgHecsTHzXVB7y18vpUt2vykk07KlVdemU9/+tOZMWNGs/c+85nP5Fvf+lZGjx6d2bNn56STTsqLL76Y66+/fpPHqqury+LFi5MkPXr0yLve9a5MmDAhH/nIR5q2WbVqVS6++OL8+Mc/zqJFi9KnT5/ss88+Oe2003LsscemoqKiZZ/3Taitrc3SpUvTt2/fprXx48dn4MCBuemmm1JdXZ0ePXpk6dKl6d17C//vCAAAALAVc9t1B1JbW5s5c+bk//v//r+mtZdffjk/+MEPsvPOO7foWF/+8pezdOnS3HPPPXnve9+bkSNH5s4770ySvPjiixk2bFj++7//OxMmTMjChQtz6623ZuTIkTnnnHOycmXLwumb1alTp9TU1KRz57+19MceeyyHHXZY3vGOd6RPnz6pqqpKTU3Nm4qi9fX1rTEuAAAAwFZDfOxA3vOe96S2tjbXXXdd09p1112XnXfeOYMGDWrRsXr27JmamprsueeemT59erp3757/+Z//SZKcd955WbRoUX7/+99n9OjR6d+/f/bcc8+MGzcu9957b6qrqzd5zKlTp2bffffNNttsk9ra2px22mlZvXp10/uLFy/Ohz70oWy77bbZZptt8u53vzs///nPkyQvvPBCTjzxxGy//fbp3r179thjj8yaNSvJX2+7rqioyL333tv08/PPP5+TTz45FRUVmT17dubPn5+Kioq8+OKLTee7/fbbc/DBB6d79+6pra3NGWeckTVr1jS9X1dXlwsvvDCjRo1Kr1698u///u8t+jMEAAAA2NqJjx3MySef3BTlkmTmzJkZM2bMmzpm586d06VLl9TX16ehoSFz5szJiSeemB133HGjbaurq5tdgfj3Kisrc9lll+XBBx/MlVdemd/85jc555xzmt7/zGc+k3Xr1uXWW2/NAw88kIsvvrgpZJ5//vl56KGHctNNN+Xhhx/Ot7/97Wa3Wb/q1Vuwe/XqlWnTpmXp0qUZOXLkRts99thjOfLII3P88cfn/vvvz9y5c3P77bfn9NNPb7bdJZdckgEDBuSee+7J+eef36I/NwAAAICtne987GA+8YlPZMKECU3f2XjHHXdkzpw5mT9//hs6Xn19fS699NKsXLkyhx12WJ577rm88MIL2WuvvVp8rL9/8ExdXV0uuuiinHLKKfnWt76VJFmyZEmOP/747LvvvkmSXXfdtWn7JUuWZNCgQRk8eHDT/pvy6i3YFRUV6d27d2pqaja53eTJk3PiiSc2zbTHHnvksssuy6GHHppvf/vb6datW5LksMMOy+c+97kWf1YAAAAAxMcOZ/vtt89RRx2V2bNnp7GxMUcdddQmrxD8Z77whS/kP//zP/Pyyy+nuro6U6ZMyVFHHZXly5e/4dl+/etfZ/LkyXnkkUeyatWqvPLKK3n55Zezdu3a9OjRI2eccUZOPfXU/PKXv8zw4cNz/PHHZ7/99kuSnHrqqTn++OOzcOHCvP/9788xxxyTYcOGveFZ7rvvvtx///25+uqrm9YaGxvT0NCQJ554InvvvXeSNMVOAAAA2Gxb+qG1vDW18GHCHZXbrjugk08+ObNnz86VV16Zk08++Q0d4/Of/3zuvffePPXUU3nhhRfyhS98Iclf42afPn3yyCOPtOh4ixYtygc/+MHst99++fGPf5wFCxZk+vTpSf72IJdPfepTefzxx/PJT34yDzzwQAYPHpzLL788SfKBD3wgixcvzmc/+9k888wzOfzww3P22We/oc+WJKtXr86nP/3p3HvvvU2v++67L3/+85+z2267NW23zTbbvOFzAAAAAGztxMcO6Mgjj0x9fX3Wr1+fESNGvKFj9O3bN7vvvvtGT4iurKzMRz/60Vx99dV55plnNtpv9erVeeWVVzZaX7BgQRoaGnLppZfmwAMPzJ577rnJ/Wtra3PKKafkuuuuy+c+97lcccUVTe9tv/32GT16dK666qpMmzYt3/3ud9/QZ0v++nCehx56KLvvvvtGr6qqqjd8XAAAAAD+xm3XHVCnTp3y8MMPN/28KStXrsy9997bbO1tb3tbamtr/+nxv/KVr2T+/Pk54IAD8pWvfCWDBw9Oly5dctttt2Xy5Mn5wx/+kD59+jTbZ/fdd8/69etz+eWX50Mf+lDuuOOOzJgxo9k2Z511Vj7wgQ9kzz33zAsvvJDf/va3Tbc/T5w4Mfvvv3/e/e53Z926dfnZz37W9N4b8YUvfCEHHnhgTj/99HzqU5/KNttsk4ceeii/+tWv8s1vfvMNHxcAAACAvxEfO6hevXq97vvz58/PoEGDmq2NHTs23/ve9/7psbfbbrv87ne/y5QpU3LRRRdl8eLF2XbbbbPvvvvma1/7Wnr33vi7LQYMGJCpU6fm4osvzoQJE3LIIYdk8uTJGTVqVNM2GzZsyGc+85k89dRT6dWrV4488sh8/etfT5JUVVVlwoQJWbRoUbp3756DDz44c+bM2Zw/ik3ab7/9csstt+SLX/xiDj744DQ2Nma33Xbb5JOxAQAAAHhjKhobGxvbeogtadWqVendu3dWrly5UaB7+eWX88QTT2SXXXZpetox/DP+3gAAAHXn3tjWI/AWsGjKUX/9wQNnSDr0A2der6/9I9/5CAAAAAAUIT4CAAAAAEWIjwAAAABAEeIjAAAAAFCE+AgAAAAAFCE+bsJW9gBw3iR/XwAAAAA2TXz8O126dEmSrF27to0noT159e/Lq39/AAAAAPirzm09wFtJp06d0qdPn6xYsSJJ0qNHj1RUVLTxVLxVNTY2Zu3atVmxYkX69OmTTp06tfVIAAAAAG8p4uM/qKmpSZKmAAn/TJ8+fZr+3gAAAADwN+LjP6ioqMgOO+yQt7/97Vm/fn1bj8NbXJcuXVzxCAAAAPAaxMfX0KlTJ1EJAAAAAN4ED5wBAAAAAIoQHwEAAACAIsRHAAAAAKAI8REAAAAAKEJ8BAAAAACKEB8BAAAAgCLERwAAAACgCPERAAAAAChCfAQAAAAAihAfAQAAAIAixEcAAAAAoAjxEQAAAAAoQnwEAAAAAIoQHwEAAACAIsRHAAAAAKAI8REAAAAAKEJ8BAAAAACKEB8BAAAAgCLERwAAAACgCPERAAAAAChCfAQAAAAAihAfAQAAAIAixEcAAAAAoAjxEQAAAAAoQnwEAAAAAIoQHwEAAACAIsRHAAAAAKAI8REAAAAAKEJ8BAAAAACKEB8BAAAAgCLeEvFx+vTpqaurS7du3XLAAQfk7rvvfs1tZ8+enYqKimavbt26bcFpAQAAAIDN0ebxce7cuRk/fnwmTZqUhQsXZsCAARkxYkRWrFjxmvv06tUrS5cubXotXrx4C04MAAAAAGyONo+PU6dOzbhx4zJmzJj0798/M2bMSI8ePTJz5szX3KeioiI1NTVNr379+m3BiQEAAACAzdGm8bG+vj4LFizI8OHDm9YqKyszfPjw3HXXXa+53+rVq/POd74ztbW1Ofroo/Pggw++5rbr1q3LqlWrmr0AAAAAgPLaND4+99xz2bBhw0ZXLvbr1y/Lli3b5D7vete7MnPmzNxwww256qqr0tDQkGHDhuWpp57a5PaTJ09O7969m161tbWt/jkAAAAAgI21+W3XLTV06NCMGjUqAwcOzKGHHprrrrsu22+/fb7zne9scvsJEyZk5cqVTa8nn3xyC08MAAAAAFunzm158r59+6ZTp05Zvnx5s/Xly5enpqZms47RpUuXDBo0KI8++ugm3+/atWu6du36pmcFAAAAAFqmTa98rKqqyv7775958+Y1rTU0NGTevHkZOnToZh1jw4YNeeCBB7LDDjuUGhMAAAAAeAPa9MrHJBk/fnxGjx6dwYMHZ8iQIZk2bVrWrFmTMWPGJElGjRqVnXbaKZMnT06SfPnLX86BBx6Y3XffPS+++GK+9rWvZfHixfnUpz7Vlh8DAAAAAPgHbR4fR44cmWeffTYTJ07MsmXLMnDgwNx8881ND6FZsmRJKiv/doHmCy+8kHHjxmXZsmXZdttts//+++fOO+9M//792+ojAAAAAACbUNHY2NjY1kNsSatWrUrv3r2zcuXK9OrVq63HAQAAoAOoO/fGth6Bt4BFU4766w8X9G7bQXhruGBlW09QTEv6Wrt72jUAAAAA0D6IjwAAAABAEeIjAAAAAFCE+AgAAAAAFCE+AgAAAABFiI8AAAAAQBHiIwAAAABQhPgIAAAAABTRua0HoIy6c29s6xF4C1g05ai2HgEAAADYirnyEQAAAAAoQnwEAAAAAIoQHwEAAACAIsRHAAAAAKAI8REAAAAAKEJ8BAAAAACKEB8BAAAAgCLERwAAAACgCPERAAAAAChCfAQAAAAAiujc1gMAhV3Qu60n4K3ggpVtPQEAAABbIVc+AgAAAABFiI8AAAAAQBHiIwAAAABQhPgIAAAAABQhPgIAAAAARYiPAAAAAEAR4iMAAAAAUIT4CAAAAAAUIT4CAAAAAEWIjwAAAABAEeIjAAAAAFCE+AgAAAAAFCE+AgAAAABFiI8AAAAAQBHiIwAAAABQhPgIAAAAABQhPgIAAAAARYiPAAAAAEAR4iMAAAAAUIT4CAAAAAAUIT4CAAAAAEWIjwAAAABAEeIjAAAAAFCE+AgAAAAAFCE+AgAAAABFiI8AAAAAQBHiIwAAAABQhPgIAAAAABQhPgIAAAAARYiPAAAAAEAR4iMAAAAAUIT4CAAAAAAUIT4CAAAAAEWIjwAAAABAEeIjAAAAAFCE+AgAAAAAFCE+AgAAAABFiI8AAAAAQBHiIwAAAABQhPgIAAAAABQhPgIAAAAARYiPAAAAAEAR4iMAAAAAUIT4CAAAAAAUIT4CAAAAAEWIjwAAAABAEeIjAAAAAFCE+AgAAAAAFCE+AgAAAABFiI8AAAAAQBHiIwAAAABQhPgIAAAAABQhPgIAAAAARYiPAAAAAEAR4iMAAAAAUIT4CAAAAAAUIT4CAAAAAEWIjwAAAABAEeIjAAAAAFCE+AgAAAAAFCE+AgAAAABFiI8AAAAAQBHiIwAAAABQhPgIAAAAABQhPgIAAAAARYiPAAAAAEAR4iMAAAAAUIT4CAAAAAAUIT4CAAAAAEWIjwAAAABAEeIjAAAAAFCE+AgAAAAAFCE+AgAAAABFiI8AAAAAQBHiIwAAAABQhPgIAAAAABQhPgIAAAAARYiPAAAAAEAR4iMAAAAAUIT4CAAAAAAUIT4CAAAAAEWIjwAAAABAEeIjAAAAAFCE+AgAAAAAFCE+AgAAAABFiI8AAAAAQBHiIwAAAABQhPgIAAAAABQhPgIAAAAARbwl4uP06dNTV1eXbt265YADDsjdd9+9WfvNmTMnFRUVOeaYY8oOCAAAAAC0WJvHx7lz52b8+PGZNGlSFi5cmAEDBmTEiBFZsWLF6+63aNGinH322Tn44IO30KQAAAAAQEu0eXycOnVqxo0blzFjxqR///6ZMWNGevTokZkzZ77mPhs2bMiJJ56YL33pS9l111234LQAAAAAwOZq0/hYX1+fBQsWZPjw4U1rlZWVGT58eO66667X3O/LX/5y3v72t2fs2LH/9Bzr1q3LqlWrmr0AAAAAgPLaND4+99xz2bBhQ/r169dsvV+/flm2bNkm97n99tvzf//v/80VV1yxWeeYPHlyevfu3fSqra1903MDAAAAAP9cm9923RIvvfRSPvnJT+aKK65I3759N2ufCRMmZOXKlU2vJ598svCUAAAAAECSdG7Lk/ft2zedOnXK8uXLm60vX748NTU1G23/2GOPZdGiRfnQhz7UtNbQ0JAk6dy5c/70pz9lt912a7ZP165d07Vr1wLTAwAAAACvp02vfKyqqsr++++fefPmNa01NDRk3rx5GTp06Ebb77XXXnnggQdy7733Nr3+7d/+Le973/ty7733uqUaAAAAAN5C2vTKxyQZP358Ro8encGDB2fIkCGZNm1a1qxZkzFjxiRJRo0alZ122imTJ09Ot27dss8++zTbv0+fPkmy0ToAAAAA0LbaPD6OHDkyzz77bCZOnJhly5Zl4MCBufnmm5seQrNkyZJUVrarr6YEAAAAAPIWiI9Jcvrpp+f000/f5Hvz589/3X1nz57d+gMBAAAAAG+aSwoBAAAAgCLERwAAAACgCPERAAAAAChCfAQAAAAAihAfAQAAAIAixEcAAAAAoAjxEQAAAAAoQnwEAAAAAIoQHwEAAACAIsRHAAAAAKAI8REAAAAAKEJ8BAAAAACKEB8BAAAAgCLERwAAAACgCPERAAAAAChCfAQAAAAAihAfAQAAAIAixEcAAAAAoAjxEQAAAAAoQnwEAAAAAIoQHwEAAACAIsRHAAAAAKAI8REAAAAAKEJ8BAAAAACKEB8BAAAAgCLERwAAAACgCPERAAAAAChCfAQAAAAAihAfAQAAAIAixEcAAAAAoAjxEQAAAAAoQnwEAAAAAIoQHwEAAACAIsRHAAAAAKAI8REAAAAAKEJ8BAAAAACKEB8BAAAAgCLERwAAAACgCPERAAAAAChCfAQAAAAAihAfAQAAAIAixEcAAAAAoAjxEQAAAAAoQnwEAAAAAIoQHwEAAACAIsRHAAAAAKAI8REAAAAAKEJ8BAAAAACKEB8BAAAAgCLERwAAAACgCPERAAAAAChCfAQAAAAAihAfAQAAAIAixEcAAAAAoAjxEQAAAAAoQnwEAAAAAIoQHwEAAACAIsRHAAAAAKAI8REAAAAAKEJ8BAAAAACKEB8BAAAAgCLERwAAAACgCPERAAAAAChCfAQAAAAAihAfAQAAAIAixEcAAAAAoAjxEQAAAAAoQnwEAAAAAIoQHwEAAACAIsRHAAAAAKAI8REAAAAAKEJ8BAAAAACKEB8BAAAAgCLERwAAAACgCPERAAAAAChCfAQAAAAAihAfAQAAAIAixEcAAAAAoAjxEQAAAAAoQnwEAAAAAIp4Q/HxlVdeya9//et85zvfyUsvvZQkeeaZZ7J69epWHQ4AAAAAaL86t3SHxYsX58gjj8ySJUuybt26HHHEEenZs2cuvvjirFu3LjNmzCgxJwAAAADQzrT4ysczzzwzgwcPzgsvvJDu3bs3rR977LGZN29eqw4HAAAAALRfLb7y8bbbbsudd96ZqqqqZut1dXV5+umnW20wAAAAAKB9a/GVjw0NDdmwYcNG60899VR69uzZKkMBAAAAAO1fi+Pj+9///kybNq3p94qKiqxevTqTJk3Kv/7rv7bmbAAAAABAO9bi264vvfTSjBgxIv3798/LL7+cj3/84/nzn/+cvn375oc//GGJGQEAAACAdqjF8fEd73hH7rvvvsydOzf33XdfVq9enbFjx+bEE09s9gAaAAAAAGDr1uL4mCSdO3fOiSeemBNPPLG15wEAAAAAOogWf+fj5MmTM3PmzI3WZ86cmYsvvrhVhgIAAAAA2r8Wx8fvfOc72WuvvTZaf/e7350ZM2a0ylAAAAAAQPvX4vi4bNmy7LDDDhutb7/99lm6dGmrDAUAAAAAtH8tjo+1tbW54447Nlq/4447suOOO7bKUAAAAABA+9fiB86MGzcuZ511VtavX5/DDjssSTJv3rycc845+dznPtfqAwIAAAAA7VOL4+PnP//5PP/88znttNNSX1+fJOnWrVu+8IUvZMKECa0+IAAAAADQPrU4PlZUVOTiiy/O+eefn4cffjjdu3fPHnvska5du5aYDwAAAABop1ocH19VXV2d9773va05CwAAAADQgbQ4Pq5ZsyZTpkzJvHnzsmLFijQ0NDR7//HHH2+14QAAAACA9qvF8fFTn/pUbrnllnzyk5/MDjvskIqKihJzAQAAAADtXIvj40033ZQbb7wxBx10UIl5AAAAAIAOorKlO2y77bbZbrvtSswCAAAAAHQgLY6PF154YSZOnJi1a9eWmAcAAAAA6CBafNv1pZdemsceeyz9+vVLXV1dunTp0uz9hQsXttpwAAAAAED71eL4eMwxxxQYAwAAAADoaFocHydNmlRiDgAAAACgg2nxdz4CAAAAAGyOFl/5uGHDhnz961/PNddckyVLlqS+vr7Z+3/5y19abTgAAAAAoP1q8ZWPX/rSlzJ16tSMHDkyK1euzPjx43PcccelsrIyF1xwQYERAQAAAID2qMXx8eqrr84VV1yRz33uc+ncuXM+9rGP5Xvf+14mTpyY3/3udyVmBAAAAADaoRbHx2XLlmXfffdNklRXV2flypVJkg9+8IO58cYbW3c6AAAAAKDdanF8fMc73pGlS5cmSXbbbbf88pe/TJL84Q9/SNeuXd/QENOnT09dXV26deuWAw44IHffffdrbnvddddl8ODB6dOnT7bZZpsMHDgw3//+99/QeQEAAACAclocH4899tjMmzcvSfIf//EfOf/887PHHntk1KhROfnkk1s8wNy5czN+/PhMmjQpCxcuzIABAzJixIisWLFik9tvt912+eIXv5i77ror999/f8aMGZMxY8bkF7/4RYvPDQAAAACU0+KnXU+ZMqXp55EjR+ad73xn7rzzzuyxxx750Ic+1OIBpk6dmnHjxmXMmDFJkhkzZuTGG2/MzJkzc+655260/f/5P/+n2e9nnnlmrrzyytx+++0ZMWJEi88PAAAAAJTR4isfb7311rzyyitNvx944IEZP358PvCBD+TWW29t0bHq6+uzYMGCDB8+/G8DVVZm+PDhueuuu/7p/o2NjZk3b17+9Kc/5ZBDDtnkNuvWrcuqVauavQAAAACA8locH9/3vvflL3/5y0brK1euzPve974WHeu5557Lhg0b0q9fv2br/fr1y7Jly15zv5UrV6a6ujpVVVU56qijcvnll+eII47Y5LaTJ09O7969m161tbUtmhEAAAAAeGNaHB8bGxtTUVGx0frzzz+fbbbZplWG+md69uyZe++9N3/4wx/yla98JePHj8/8+fM3ue2ECROycuXKpteTTz65RWYEAAAAgK3dZn/n43HHHZckqaioyEknndTsydYbNmzI/fffn2HDhrXo5H379k2nTp2yfPnyZuvLly9PTU3Na+5XWVmZ3XffPUkycODAPPzww5k8efJG3weZJF27dn3DT+EGAAAAAN64zb7y8dXblhsbG9OzZ89mtzLX1NTk3//933PVVVe16ORVVVXZf//9m56enSQNDQ2ZN29ehg4dutnHaWhoyLp161p0bgAAAACgrM2+8nHWrFlJkrq6upx99tmtdov1+PHjM3r06AwePDhDhgzJtGnTsmbNmqanX48aNSo77bRTJk+enOSv3+E4ePDg7Lbbblm3bl1+/vOf5/vf/36+/e1vt8o8AAAAAEDr2Oz4+KpzzjknjY2NTb8vXrw4P/nJT9K/f/+8//3vb/EAI0eOzLPPPpuJEydm2bJlGThwYG6++eamh9AsWbIklZV/u0BzzZo1Oe200/LUU0+le/fu2WuvvXLVVVdl5MiRLT43AAAAAFBOi+Pj0UcfneOOOy6nnHJKXnzxxQwZMiRVVVV57rnnMnXq1Jx66qktHuL000/P6aefvsn3/vFBMhdddFEuuuiiFp8DAAAAANiyWvy064ULF+bggw9OkvzoRz9KTU1NFi9enP/+7//OZZdd1uoDAgAAAADtU4vj49q1a9OzZ88kyS9/+cscd9xxqayszIEHHpjFixe3+oAAAAAAQPvU4vi4++675/rrr8+TTz6ZX/ziF03f87hixYr06tWr1QcEAAAAANqnFsfHiRMn5uyzz05dXV0OOOCADB06NMlfr4IcNGhQqw8IAAAAALRPLX7gzIc//OH8y7/8S5YuXZoBAwY0rR9++OE59thjW3U4AAAAAKD9anF8TJKamprU1NQ0WxsyZEirDAQAAAAAdAybFR+PO+64zJ49O7169cpxxx33utted911rTIYAAAAANC+bVZ87N27dyoqKpp+BgAAAAD4ZzYrPs6aNWuTPwMAAAAAvJYWP+0aAAAAAGBzbNaVj4MGDWq67fqfWbhw4ZsaCAAAAADoGDYrPh5zzDFNP7/88sv51re+lf79+2fo0KFJkt/97nd58MEHc9pppxUZEgAAAABofzYrPk6aNKnp50996lM544wzcuGFF260zZNPPtm60wEAAAAA7VaLv/Px2muvzahRozZa/8QnPpEf//jHrTIUAAAAAND+tTg+du/ePXfcccdG63fccUe6devWKkMBAAAAAO3fZt12/ffOOuusnHrqqVm4cGGGDBmSJPn973+fmTNn5vzzz2/1AQEAAACA9qnF8fHcc8/Nrrvumm984xu56qqrkiR77713Zs2alRNOOKHVBwQAAAAA2qcWx8ckOeGEE4RGAAAAAOB1tfg7HwEAAAAANof4CAAAAAAUIT4CAAAAAEWIjwAAAABAEeIjAAAAAFBEi592vWHDhsyePTvz5s3LihUr0tDQ0Oz93/zmN602HAAAAADQfrU4Pp555pmZPXt2jjrqqOyzzz6pqKgoMRcAAAAA0M61OD7OmTMn11xzTf71X/+1xDwAAAAAQAfR4u98rKqqyu67715iFgAAAACgA2lxfPzc5z6Xb3zjG2lsbCwxDwAAAADQQbT4tuvbb789v/3tb3PTTTfl3e9+d7p06dLs/euuu67VhgMAAAAA2q8Wx8c+ffrk2GOPLTELAAAAANCBtDg+zpo1q8QcAAAAAEAH0+LvfAQAAAAA2BwtvvIxSX70ox/lmmuuyZIlS1JfX9/svYULF7bKYAAAAABA+9biKx8vu+yyjBkzJv369cs999yTIUOG5G1ve1sef/zxfOADHygxIwAAAADQDrU4Pn7rW9/Kd7/73Vx++eWpqqrKOeeck1/96lc544wzsnLlyhIzAgAAAADtUIvj45IlSzJs2LAkSffu3fPSSy8lST75yU/mhz/8YetOBwAAAAC0Wy2OjzU1NfnLX/6SJNl5553zu9/9LknyxBNPpLGxsXWnAwAAAADarRbHx8MOOyw//elPkyRjxozJZz/72RxxxBEZOXJkjj322FYfEAAAAABon1r8tOvvfve7aWhoSJJ85jOfydve9rbceeed+bd/+7d8+tOfbvUBAQAAAID2qcXxsbKyMpWVf7tg8qMf/Wg++tGPtupQAAAAAED71+LbrpPktttuyyc+8YkMHTo0Tz/9dJLk+9//fm6//fZWHQ4AAAAAaL9aHB9//OMfZ8SIEenevXvuueeerFu3LkmycuXK/Nd//VerDwgAAAAAtE8tjo8XXXRRZsyYkSuuuCJdunRpWj/ooIOycOHCVh0OAAAAAGi/Whwf//SnP+WQQw7ZaL1379558cUXW2MmAAAAAKADaHF8rKmpyaOPPrrR+u23355dd921VYYCAAAAANq/FsfHcePG5cwzz8zvf//7VFRU5JlnnsnVV1+ds88+O6eeemqJGQEAAACAdqhzS3c499xz09DQkMMPPzxr167NIYcckq5du+bss8/Of/zHf5SYEQAAAABoh1ocHysqKvLFL34xn//85/Poo49m9erV6d+/f6qrq0vMBwAAAAC0Uy2Oj6+qqqpK//79W3MWAAAAAKAD2ez4ePLJJ2/WdjNnznzDwwAAAAAAHcdmx8fZs2fnne98ZwYNGpTGxsaSMwEAAAAAHcBmx8dTTz01P/zhD/PEE09kzJgx+cQnPpHtttuu5GwAAAAAQDtWubkbTp8+PUuXLs0555yT//mf/0ltbW1OOOGE/OIXv3AlJAAAAACwkc2Oj0nStWvXfOxjH8uvfvWrPPTQQ3n3u9+d0047LXV1dVm9enWpGQEAAACAdqhF8bHZjpWVqaioSGNjYzZs2NCaMwEAAAAAHUCL4uO6devywx/+MEcccUT23HPPPPDAA/nmN7+ZJUuWpLq6utSMAAAAAEA7tNkPnDnttNMyZ86c1NbW5uSTT84Pf/jD9O3bt+RsAAAAAEA7ttnxccaMGdl5552z66675pZbbsktt9yyye2uu+66VhsOAAAAAGi/Njs+jho1KhUVFSVnAQAAAAA6kM2Oj7Nnzy44BgAAAADQ0bzhp10DAAAAALwe8REAAAAAKEJ8BAAAAACKEB8BAAAAgCLERwAAAACgCPERAAAAAChCfAQAAAAAihAfAQAAAIAixEcAAAAAoAjxEQAAAAAoQnwEAAAAAIoQHwEAAACAIsRHAAAAAKAI8REAAAAAKEJ8BAAAAACKEB8BAAAAgCLERwAAAACgCPERAAAAAChCfAQAAAAAihAfAQAAAIAixEcAAAAAoAjxEQAAAAAoQnwEAAAAAIoQHwEAAACAIsRHAAAAAKAI8REAAAAAKEJ8BAAAAACKEB8BAAAAgCLERwAAAACgCPERAAAAAChCfAQAAAAAihAfAQAAAIAixEcAAAAAoAjxEQAAAAAoQnwEAAAAAIoQHwEAAACAIsRHAAAAAKAI8REAAAAAKEJ8BAAAAACKEB8BAAAAgCLERwAAAACgCPERAAAAAChCfAQAAAAAihAfAQAAAIAixEcAAAAAoAjxEQAAAAAoQnwEAAAAAIoQHwEAAACAIsRHAAAAAKCIt0R8nD59eurq6tKtW7cccMABufvuu19z2yuuuCIHH3xwtt1222y77bYZPnz4624PAAAAALSNNo+Pc+fOzfjx4zNp0qQsXLgwAwYMyIgRI7JixYpNbj9//vx87GMfy29/+9vcddddqa2tzfvf//48/fTTW3hyAAAAAOD1tHl8nDp1asaNG5cxY8akf//+mTFjRnr06JGZM2ducvurr746p512WgYOHJi99tor3/ve99LQ0JB58+Zt4ckBAAAAgNfTpvGxvr4+CxYsyPDhw5vWKisrM3z48Nx1112bdYy1a9dm/fr12W677UqNCQAAAAC8AZ3b8uTPPfdcNmzYkH79+jVb79evXx555JHNOsYXvvCF7Ljjjs0C5t9bt25d1q1b1/T7qlWr3vjAAAAAAMBma/Pbrt+MKVOmZM6cOfnJT36Sbt26bXKbyZMnp3fv3k2v2traLTwlAAAAAGyd2jQ+9u3bN506dcry5cubrS9fvjw1NTWvu+8ll1ySKVOm5Je//GX222+/19xuwoQJWblyZdPrySefbJXZAQAAAIDX16bxsaqqKvvvv3+zh8W8+vCYoUOHvuZ+X/3qV3PhhRfm5ptvzuDBg1/3HF27dk2vXr2avQAAAACA8tr0Ox+TZPz48Rk9enQGDx6cIUOGZNq0aVmzZk3GjBmTJBk1alR22mmnTJ48OUly8cUXZ+LEifnBD36Qurq6LFu2LElSXV2d6urqNvscAAAAAEBzbR4fR44cmWeffTYTJ07MsmXLMnDgwNx8881ND6FZsmRJKiv/doHmt7/97dTX1+fDH/5ws+NMmjQpF1xwwZYcHQAAAAB4HW0eH5Pk9NNPz+mnn77J9+bPn9/s90WLFpUfCAAAAAB409r1064BAAAAgLcu8REAAAAAKEJ8BAAAAACKEB8BAAAAgCLERwAAAACgCPERAAAAAChCfAQAAAAAihAfAQAAAIAixEcAAAAAoAjxEQAAAAAoQnwEAAAAAIoQHwEAAACAIsRHAAAAAKAI8REAAAAAKEJ8BAAAAACKEB8BAAAAgCLERwAAAACgCPERAAAAAChCfAQAAAAAihAfAQAAAIAixEcAAAAAoAjxEQAAAAAoQnwEAAAAAIoQHwEAAACAIsRHAAAAAKAI8REAAAAAKEJ8BAAAAACKEB8BAAAAgCLERwAAAACgCPERAAAAAChCfAQAAAAAihAfAQAAAIAixEcAAAAAoAjxEQAAAAAoQnwEAAAAAIoQHwEAAACAIsRHAAAAAKAI8REAAAAAKEJ8BAAAAACKEB8BAAAAgCLERwAAAACgCPERAAAAAChCfAQAAAAAihAfAQAAAIAixEcAAAAAoAjxEQAAAAAoQnwEAAAAAIoQHwEAAACAIsRHAAAAAKAI8REAAAAAKEJ8BAAAAACKEB8BAAAAgCLERwAAAACgCPERAAAAAChCfAQAAAAAihAfAQAAAIAixEcAAAAAoAjxEQAAAAAoQnwEAAAAAIoQHwEAAACAIsRHAAAAAKAI8REAAAAAKEJ8BAAAAACKEB8BAAAAgCLERwAAAACgCPERAAAAAChCfAQAAAAAihAfAQAAAIAixEcAAAAAoAjxEQAAAAAoQnwEAAAAAIoQHwEAAACAIsRHAAAAAKAI8REAAAAAKEJ8BAAAAACKEB8BAAAAgCLERwAAAACgCPERAAAAAChCfAQAAAAAihAfAQAAAIAixEcAAAAAoAjxEQAAAAAoQnwEAAAAAIoQHwEAAACAIsRHAAAAAKAI8REAAAAAKEJ8BAAAAACKEB8BAAAAgCLERwAAAACgCPERAAAAAChCfAQAAAAAihAfAQAAAIAixEcAAAAAoAjxEQAAAAAoQnwEAAAAAIoQHwEAAACAIsRHAAAAAKAI8REAAAAAKEJ8BAAAAACKEB8BAAAAgCLERwAAAACgCPERAAAAAChCfAQAAAAAihAfAQAAAIAixEcAAAAAoAjxEQAAAAAoQnwEAAAAAIoQHwEAAACAIsRHAAAAAKAI8REAAAAAKKLN4+P06dNTV1eXbt265YADDsjdd9/9mts++OCDOf7441NXV5eKiopMmzZtyw0KAAAAALRIm8bHuXPnZvz48Zk0aVIWLlyYAQMGZMSIEVmxYsUmt1+7dm123XXXTJkyJTU1NVt4WgAAAACgJdo0Pk6dOjXjxo3LmDFj0r9//8yYMSM9evTIzJkzN7n9e9/73nzta1/LRz/60XTt2nULTwsAAAAAtESbxcf6+vosWLAgw4cP/9swlZUZPnx47rrrrlY7z7p167Jq1apmLwAAAACgvDaLj88991w2bNiQfv36NVvv169fli1b1mrnmTx5cnr37t30qq2tbbVjAwAAAACvrc0fOFPahAkTsnLlyqbXk08+2dYjAQAAAMBWoXNbnbhv377p1KlTli9f3mx9+fLlrfowma5du/p+SAAAAABoA2125WNVVVX233//zJs3r2mtoaEh8+bNy9ChQ9tqLAAAAACglbTZlY9JMn78+IwePTqDBw/OkCFDMm3atKxZsyZjxoxJkowaNSo77bRTJk+enOSvD6l56KGHmn5++umnc++996a6ujq77757m30OAAAAAGBjbRofR44cmWeffTYTJ07MsmXLMnDgwNx8881ND6FZsmRJKiv/dnHmM888k0GDBjX9fskll+SSSy7JoYcemvnz52/p8QEAAACA19Gm8TFJTj/99Jx++umbfO8fg2JdXV0aGxu3wFQAAAAAwJvV4Z92DQAAAAC0DfERAAAAAChCfAQAAAAAihAfAQAAAIAixEcAAAAAoAjxEQAAAAAoQnwEAAAAAIoQHwEAAACAIsRHAAAAAKAI8REAAAAAKEJ8BAAAAACKEB8BAAAAgCLERwAAAACgCPERAAAAAChCfAQAAAAAihAfAQAAAIAixEcAAAAAoAjxEQAAAAAoQnwEAAAAAIoQHwEAAACAIsRHAAAAAKAI8REAAAAAKEJ8BAAAAACKEB8BAAAAgCLERwAAAACgCPERAAAAAChCfAQAAAAAihAfAQAAAIAixEcAAAAAoAjxEQAAAAAoQnwEAAAAAIoQHwEAAACAIsRHAAAAAKAI8REAAAAAKEJ8BAAAAACKEB8BAAAAgCLERwAAAACgCPERAAAAAChCfAQAAAAAihAfAQAAAIAixEcAAAAAoAjxEQAAAAAoQnwEAAAAAIoQHwEAAACAIsRHAAAAAKAI8REAAAAAKEJ8BAAAAACKEB8BAAAAgCLERwAAAACgCPERAAAAAChCfAQAAAAAihAfAQAAAIAixEcAAAAAoAjxEQAAAAAoQnwEAAAAAIoQHwEAAACAIsRHAAAAAKAI8REAAAAAKEJ8BAAAAACKEB8BAAAAgCLERwAAAACgCPERAAAAAChCfAQAAAAAihAfAQAAAIAixEcAAAAAoAjxEQAAAAAoQnwEAAAAAIoQHwEAAACAIsRHAAAAAKAI8REAAAAAKEJ8BAAAAACKEB8BAAAAgCLERwAAAACgCPERAAAAAChCfAQAAAAAihAfAQAAAIAixEcAAAAAoAjxEQAAAAAoQnwEAAAAAIoQHwEAAACAIsRHAAAAAKAI8REAAAAAKEJ8BAAAAACKEB8BAAAAgCLERwAAAACgCPERAAAAAChCfAQAAAAAihAfAQAAAIAixEcAAAAAoAjxEQAAAAAoQnwEAAAAAIoQHwEAAACAIsRHAAAAAKAI8REAAAAAKEJ8BAAAAACKEB8BAAAAgCLERwAAAACgCPERAAAAAChCfAQAAAAAihAfAQAAAIAixEcAAAAAoAjxEQAAAAAoQnwEAAAAAIoQHwEAAACAIsRHAAAAAKAI8REAAAAAKEJ8BAAAAACKEB8BAAAAgCLERwAAAACgCPERAAAAACjiLREfp0+fnrq6unTr1i0HHHBA7r777tfd/tprr81ee+2Vbt26Zd99983Pf/7zLTQpAAAAALC52jw+zp07N+PHj8+kSZOycOHCDBgwICNGjMiKFSs2uf2dd96Zj33sYxk7dmzuueeeHHPMMTnmmGPy//7f/9vCkwMAAAAAr6fN4+PUqVMzbty4jBkzJv3798+MGTPSo0ePzJw5c5Pbf+Mb38iRRx6Zz3/+89l7771z4YUX5j3veU+++c1vbuHJAQAAAIDX07ktT15fX58FCxZkwoQJTWuVlZUZPnx47rrrrk3uc9ddd2X8+PHN1kaMGJHrr79+k9uvW7cu69ata/p95cqVSZJVq1a9yenf2hrWrW3rEXgLWLVqVbKusa3H4K2gg/83DwCgrfk3GMnftQb/DiPp0P8Oe/XvemPjP/+73qbx8bnnnsuGDRvSr1+/Zuv9+vXLI488ssl9li1btsntly1btsntJ0+enC996UsbrdfW1r7BqaH96D2trSfgLWNK77aeAAAAOjz/BqOZreDfYS+99FJ69379z9mm8XFLmDBhQrMrJRsaGvKXv/wlb3vb21JRUdGGk0FZTz/9dPr375+HHnooO+20U1uPAwAA0OH5dxhbi8bGxrz00kvZcccd/+m2bRof+/btm06dOmX58uXN1pcvX56amppN7lNTU9Oi7bt27ZquXbs2W+vTp88bHxraiVcvge7Zs2d69erVxtMAAAB0fP4dxtbkn13x+Ko2feBMVVVV9t9//8ybN69praGhIfPmzcvQoUM3uc/QoUObbZ8kv/rVr15zewAAAACgbbT5bdfjx4/P6NGjM3jw4AwZMiTTpk3LmjVrMmbMmCTJqFGjstNOO2Xy5MlJkjPPPDOHHnpoLr300hx11FGZM2dO/vjHP+a73/1uW34MAAAAAOAftHl8HDlyZJ599tlMnDgxy5Yty8CBA3PzzTc3PVRmyZIlqaz82wWaw4YNyw9+8IP853/+Z84777zsscceuf7667PPPvu01UeAt6RevXrl0EMPdak/AADAFuLfYbCxisbNeSY2AAAAAEALtel3PgIAAAAAHZf4CAAAAAAUIT4CAAAAAEWIjwAAAABAEeIjdFAnnHBCOnfunIqKilRXV2fWrFltPRIAAECHdPnll6dfv37p1KlTKioqMmHChLYeCd4yxEfogM4888xce+21GTVqVG644YbU1tZm7NixefDBB9t6NAAAgA7nhRdeyB577JGzzz67rUeBt5yKxsbGxrYeAmhd1dXV2XXXXXP//fcnSV555ZV07do1RxxxRG6++eY2ng4AAKDjqqioyLnnnpvJkye39SjwluDKR+hgVq9enTVr1uSoo45qWuvcuXPq6upy3333teFkAAAAwNZGfIQO5n//93+TJLvsskuz9be97W156aWX2mIkAAAAYCslPgIAAAAARYiP0MHsueeeSZInnnii2frzzz+fnj17tsVIAAAAwFZKfIQOprq6Ottss01uvPHGprVXXnklixYtyoABA9pwMgAAAGBrIz5CBzR27Ng88MADGTduXH72s59l3333TWNjYy655JK2Hg0AAKDDWbZsWebOnZu5c+cmSR5++OHMnTs3d911VxtPBm2vorGxsbGthwBa30c+8pH85Cc/yYYNG7LNNtvkG9/4RsaOHdvWYwEAAHQ406ZNy2c/+9mN1nfbbbc8+uijbTARvHWIjwAAAABAEW67BgAAAACKEB8BAAAAgCLERwAAAACgCPERAAAAAChCfAQAAAAAihAfAQAAAIAixEcAAAAAoAjxEQAAAAAoQnwEAGCznXTSSamoqEhFRUW6dOmSfv365YgjjsjMmTPT0NCw2ceZPXt2+vTpU27Q13DSSSflmGOO2eLnBQDYWomPAAC0yJFHHpmlS5dm0aJFuemmm/K+970vZ555Zj74wQ/mlVdeaevxAAB4CxEfAQBoka5du6ampiY77bRT3vOe9+S8887LDTfckJtuuimzZ89OkkydOjX77rtvttlmm9TW1ua0007L6tWrkyTz58/PmDFjsnLlyqarKC+44IIkyfe///0MHjw4PXv2TE1NTT7+8Y9nxYoVTed+4YUXcuKJJ2b77bdP9+7ds8cee2TWrFlN7z/55JM54YQT0qdPn2y33XY5+uijs2jRoiTJBRdckCuvvDI33HBD03nnz5+/Jf7IAAC2WuIjAABv2mGHHZYBAwbkuuuuS5JUVlbmsssuy4MPPpgrr7wyv/nNb3LOOeckSYYNG5Zp06alV69eWbp0aZYuXZqzzz47SbJ+/fpceOGFue+++3L99ddn0aJFOemkk5rOc/755+ehhx7KTTfdlIcffjjf/va307dv36Z9R4wYkZ49e+a2227LHXfckerq6hx55JGpr6/P2WefnRNOOKHpys2lS5dm2LBhW/YPCgBgK9O5rQcAAKBj2GuvvXL//fcnSc4666ym9bq6ulx00UU55ZRT8q1vfStVVVXp3bt3KioqUlNT0+wYJ598ctPPu+66ay677LK8973vzerVq1NdXZ0lS5Zk0KBBGTx4cNOxXzV37tw0NDTke9/7XioqKpIks2bNSp8+fTJ//vy8//3vT/fu3bNu3bqNzgsAQBmufAQAoFU0NjY2Rb9f//rXOfzww7PTTjulZ8+e+eQnP5nnn38+a9eufd1jLFiwIB/60Iey8847p2fPnjn00EOTJEuWLEmSnHrqqZkzZ04GDhyYc845J3feeWfTvvfdd18effTR9OzZM9XV1amurs52222Xl19+OY899lihTw0AwOsRHwEAaBUPP/xwdtlllyxatCgf/OAHs99+++XHP/5xFixYkOnTpydJ6uvrX3P/NWvWZMSIEenVq1euvvrq/OEPf8hPfvKTZvt94AMfyOLFi/PZz342zzzzTA4//PCmW7ZXr16d/fffP/fee2+z1//+7//m4x//eOFPDwDAprjtGgCAN+03v/lNHnjggXz2s5/NggUL0tDQkEsvvTSVlX/9/7qvueaaZttXVVVlw4YNzdYeeeSRPP/885kyZUpqa2uTJH/84x83Otf222+f0aNHZ/To0Tn44IPz+c9/Ppdcckne8573ZO7cuXn729+eXr16bXLOTZ0XAIByXPkIAECLrFu3LsuWLcvTTz+dhQsX5r/+679y9NFH54Mf/GBGjRqV3XffPevXr8/ll1+exx9/PN///vczY8aMZseoq6vL6tWrM2/evDz33HNZu3Ztdt5551RVVTXt99Of/jQXXnhhs/0mTpyYG264IY8++mgefPDB/OxnP8vee++dJDnxxBPTt2/fHH300bntttvyxBNPZP78+TnjjDPy1FNPNZ33/vvvz5/+9Kc899xzWb9+/Zb5QwMA2EqJjwAAtMjNN9+cHXbYIXV1dTnyyCPz29/+NpdddlluuOGGdOrUKQMGDMjUqVNz8cUXZ5999snVV1+dyZMnNzvGsGHDcsopp2TkyJHZfvvt89WvfjXbb799Zs+enWuvvTb9+/fPlClTcskllzTbr6qqKhMmTMh+++2XQw45JJ06dcqcOXOSJD169Mitt96anXfeOccdd1z23nvvjB07Ni+//HLTlZDjxo3Lu971rgwePDjbb7997rjjji3zhwYAsJWqaGxsbGzrIQAAAACAjseVjwAAAABAEeIjAAAAAFCE+AgAAAAAFCE+AgAAAABFiI8AAAAAQBHiIwAAAABQhPgIAAAAABQhPgIAAAAARYiPAAAAAEAR4iMAAAAAUIT4CAAAAAAUIT4CAAAAAEX8/2DZsHfiEU6hAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 1600x900 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "svc = mean_fitness[mean_fitness[\"model\"] == \"SVC\"]\n",
    "mlp = mean_fitness[mean_fitness[\"model\"] == \"MLPClassifier\"]\n",
    "\n",
    "plt.figure(figsize=(16, 9))\n",
    "plt.xticks(mean_fitness[\"dataset_id\"])\n",
    "plt.xlabel(\"Dataset\")\n",
    "plt.ylabel(\"Mean distance\")\n",
    "\n",
    "plt.bar(x=svc[\"dataset_id\"] - 0.076, height=svc[\"mean_fitness\"] * (-1.0), width=0.15, label=\"SVC\")\n",
    "plt.bar(x=mlp[\"dataset_id\"] + 0.076, height=mlp[\"mean_fitness\"] * (-1.0), width=0.15, label=\"MLPClassifier\")\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "@deathbeds/jupyterlab-fonts": {
   "styles": {
    ":root": {
     "--jp-code-font-size": "18px",
     "--jp-content-font-size1": "18px"
    }
   }
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
