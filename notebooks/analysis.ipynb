{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4bb941d1-38d5-46ff-8a9b-1c8fac8f0136",
   "metadata": {},
   "source": [
    "# Analisi risultati\n",
    "\n",
    "Nel notebook vengono svolte alcune analisi sul dataset generato tramite varie\n",
    "simulazioni su diversi dataset e utilizzando tre diversi classificatori. In\n",
    "particolare sono stati usati una **SVM**, un **MultiLayer Perceptron** e un\n",
    "**Random Forest**. Non sono stati effettuati benchmark sulle prestazioni, si\n",
    "sta infatti considerando solo la qualità dei risultati ottenuti.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "925e79e6-f66e-4a19-beb5-f0512e49d253",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset_id</th>\n",
       "      <th>samples</th>\n",
       "      <th>features</th>\n",
       "      <th>classes</th>\n",
       "      <th>clusters</th>\n",
       "      <th>point</th>\n",
       "      <th>class</th>\n",
       "      <th>target</th>\n",
       "      <th>model</th>\n",
       "      <th>min_fitness</th>\n",
       "      <th>mean_fitness</th>\n",
       "      <th>max_fitness</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>SVC</td>\n",
       "      <td>-0.863216</td>\n",
       "      <td>-0.693211</td>\n",
       "      <td>-0.530128</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>SVC</td>\n",
       "      <td>-0.212320</td>\n",
       "      <td>-0.111060</td>\n",
       "      <td>-0.000843</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>SVC</td>\n",
       "      <td>-0.122858</td>\n",
       "      <td>-0.060963</td>\n",
       "      <td>-0.000577</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>SVC</td>\n",
       "      <td>-0.584679</td>\n",
       "      <td>-0.517216</td>\n",
       "      <td>-0.473684</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>SVC</td>\n",
       "      <td>-1.069148</td>\n",
       "      <td>-1.007200</td>\n",
       "      <td>-0.954585</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>SVC</td>\n",
       "      <td>-0.194921</td>\n",
       "      <td>-0.104197</td>\n",
       "      <td>-0.000167</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>SVC</td>\n",
       "      <td>-0.898964</td>\n",
       "      <td>-0.827281</td>\n",
       "      <td>-0.766880</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>SVC</td>\n",
       "      <td>-0.177876</td>\n",
       "      <td>-0.095933</td>\n",
       "      <td>-0.000479</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>SVC</td>\n",
       "      <td>-0.202024</td>\n",
       "      <td>-0.107771</td>\n",
       "      <td>-0.000027</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>SVC</td>\n",
       "      <td>-1.392031</td>\n",
       "      <td>-1.347967</td>\n",
       "      <td>-1.314164</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>-0.814046</td>\n",
       "      <td>-0.643415</td>\n",
       "      <td>-0.487079</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>-0.211688</td>\n",
       "      <td>-0.111412</td>\n",
       "      <td>-0.002880</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>-0.126069</td>\n",
       "      <td>-0.061999</td>\n",
       "      <td>-0.000577</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>-0.568090</td>\n",
       "      <td>-0.500289</td>\n",
       "      <td>-0.461785</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>-1.041980</td>\n",
       "      <td>-0.983040</td>\n",
       "      <td>-0.946432</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>-0.183290</td>\n",
       "      <td>-0.101152</td>\n",
       "      <td>-0.000195</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>-0.867144</td>\n",
       "      <td>-0.792772</td>\n",
       "      <td>-0.735197</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>-0.192574</td>\n",
       "      <td>-0.100331</td>\n",
       "      <td>-0.000479</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>-0.208884</td>\n",
       "      <td>-0.114066</td>\n",
       "      <td>-0.000027</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>-1.394919</td>\n",
       "      <td>-1.347551</td>\n",
       "      <td>-1.304130</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>SVC</td>\n",
       "      <td>-1.082284</td>\n",
       "      <td>-0.942620</td>\n",
       "      <td>-0.841080</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>SVC</td>\n",
       "      <td>-0.198747</td>\n",
       "      <td>-0.106387</td>\n",
       "      <td>-0.000342</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>SVC</td>\n",
       "      <td>-2.155123</td>\n",
       "      <td>-1.876064</td>\n",
       "      <td>-1.604303</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>SVC</td>\n",
       "      <td>-0.853050</td>\n",
       "      <td>-0.490955</td>\n",
       "      <td>-0.002983</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>SVC</td>\n",
       "      <td>-0.233730</td>\n",
       "      <td>-0.124862</td>\n",
       "      <td>-0.002665</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>SVC</td>\n",
       "      <td>-0.853220</td>\n",
       "      <td>-0.722796</td>\n",
       "      <td>-0.595085</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>SVC</td>\n",
       "      <td>-0.215328</td>\n",
       "      <td>-0.111755</td>\n",
       "      <td>-0.002030</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>SVC</td>\n",
       "      <td>-0.564927</td>\n",
       "      <td>-0.407560</td>\n",
       "      <td>-0.291370</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>SVC</td>\n",
       "      <td>-0.303950</td>\n",
       "      <td>-0.161250</td>\n",
       "      <td>-0.000913</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>SVC</td>\n",
       "      <td>-0.736125</td>\n",
       "      <td>-0.563592</td>\n",
       "      <td>-0.383636</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>-0.980131</td>\n",
       "      <td>-0.865489</td>\n",
       "      <td>-0.763126</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>-0.210931</td>\n",
       "      <td>-0.113191</td>\n",
       "      <td>-0.002871</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>-2.122636</td>\n",
       "      <td>-1.865527</td>\n",
       "      <td>-1.569005</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>-0.821988</td>\n",
       "      <td>-0.485629</td>\n",
       "      <td>-0.002983</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>-0.224688</td>\n",
       "      <td>-0.118700</td>\n",
       "      <td>-0.002665</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>-0.966057</td>\n",
       "      <td>-0.854572</td>\n",
       "      <td>-0.733236</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>-0.227734</td>\n",
       "      <td>-0.121283</td>\n",
       "      <td>-0.002030</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>-0.696346</td>\n",
       "      <td>-0.544574</td>\n",
       "      <td>-0.428521</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>-0.350138</td>\n",
       "      <td>-0.166886</td>\n",
       "      <td>-0.003443</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>-0.671237</td>\n",
       "      <td>-0.444487</td>\n",
       "      <td>-0.225970</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    dataset_id  samples  features  classes  clusters  point  class  target  \\\n",
       "0            0        5         2        2         1      0      1       0   \n",
       "1            0        5         2        2         1      0      1       1   \n",
       "2            0        5         2        2         1      1      0       0   \n",
       "3            0        5         2        2         1      1      0       1   \n",
       "4            0        5         2        2         1      2      1       0   \n",
       "5            0        5         2        2         1      2      1       1   \n",
       "6            0        5         2        2         1      3      1       0   \n",
       "7            0        5         2        2         1      3      1       1   \n",
       "8            0        5         2        2         1      4      0       0   \n",
       "9            0        5         2        2         1      4      0       1   \n",
       "10           0        5         2        2         1      0      1       0   \n",
       "11           0        5         2        2         1      0      1       1   \n",
       "12           0        5         2        2         1      1      0       0   \n",
       "13           0        5         2        2         1      1      0       1   \n",
       "14           0        5         2        2         1      2      1       0   \n",
       "15           0        5         2        2         1      2      1       1   \n",
       "16           0        5         2        2         1      3      1       0   \n",
       "17           0        5         2        2         1      3      1       1   \n",
       "18           0        5         2        2         1      4      0       0   \n",
       "19           0        5         2        2         1      4      0       1   \n",
       "20           1        5         2        2         2      0      1       0   \n",
       "21           1        5         2        2         2      0      1       1   \n",
       "22           1        5         2        2         2      1      1       0   \n",
       "23           1        5         2        2         2      1      1       1   \n",
       "24           1        5         2        2         2      2      0       0   \n",
       "25           1        5         2        2         2      2      0       1   \n",
       "26           1        5         2        2         2      3      0       0   \n",
       "27           1        5         2        2         2      3      0       1   \n",
       "28           1        5         2        2         2      4      0       0   \n",
       "29           1        5         2        2         2      4      0       1   \n",
       "30           1        5         2        2         2      0      1       0   \n",
       "31           1        5         2        2         2      0      1       1   \n",
       "32           1        5         2        2         2      1      1       0   \n",
       "33           1        5         2        2         2      1      1       1   \n",
       "34           1        5         2        2         2      2      0       0   \n",
       "35           1        5         2        2         2      2      0       1   \n",
       "36           1        5         2        2         2      3      0       0   \n",
       "37           1        5         2        2         2      3      0       1   \n",
       "38           1        5         2        2         2      4      0       0   \n",
       "39           1        5         2        2         2      4      0       1   \n",
       "\n",
       "            model  min_fitness  mean_fitness  max_fitness  accuracy  \n",
       "0             SVC    -0.863216     -0.693211    -0.530128       1.0  \n",
       "1             SVC    -0.212320     -0.111060    -0.000843       1.0  \n",
       "2             SVC    -0.122858     -0.060963    -0.000577       1.0  \n",
       "3             SVC    -0.584679     -0.517216    -0.473684       1.0  \n",
       "4             SVC    -1.069148     -1.007200    -0.954585       1.0  \n",
       "5             SVC    -0.194921     -0.104197    -0.000167       1.0  \n",
       "6             SVC    -0.898964     -0.827281    -0.766880       1.0  \n",
       "7             SVC    -0.177876     -0.095933    -0.000479       1.0  \n",
       "8             SVC    -0.202024     -0.107771    -0.000027       1.0  \n",
       "9             SVC    -1.392031     -1.347967    -1.314164       1.0  \n",
       "10  MLPClassifier    -0.814046     -0.643415    -0.487079       1.0  \n",
       "11  MLPClassifier    -0.211688     -0.111412    -0.002880       1.0  \n",
       "12  MLPClassifier    -0.126069     -0.061999    -0.000577       1.0  \n",
       "13  MLPClassifier    -0.568090     -0.500289    -0.461785       1.0  \n",
       "14  MLPClassifier    -1.041980     -0.983040    -0.946432       1.0  \n",
       "15  MLPClassifier    -0.183290     -0.101152    -0.000195       1.0  \n",
       "16  MLPClassifier    -0.867144     -0.792772    -0.735197       1.0  \n",
       "17  MLPClassifier    -0.192574     -0.100331    -0.000479       1.0  \n",
       "18  MLPClassifier    -0.208884     -0.114066    -0.000027       1.0  \n",
       "19  MLPClassifier    -1.394919     -1.347551    -1.304130       1.0  \n",
       "20            SVC    -1.082284     -0.942620    -0.841080       1.0  \n",
       "21            SVC    -0.198747     -0.106387    -0.000342       1.0  \n",
       "22            SVC    -2.155123     -1.876064    -1.604303       1.0  \n",
       "23            SVC    -0.853050     -0.490955    -0.002983       1.0  \n",
       "24            SVC    -0.233730     -0.124862    -0.002665       1.0  \n",
       "25            SVC    -0.853220     -0.722796    -0.595085       1.0  \n",
       "26            SVC    -0.215328     -0.111755    -0.002030       1.0  \n",
       "27            SVC    -0.564927     -0.407560    -0.291370       1.0  \n",
       "28            SVC    -0.303950     -0.161250    -0.000913       1.0  \n",
       "29            SVC    -0.736125     -0.563592    -0.383636       1.0  \n",
       "30  MLPClassifier    -0.980131     -0.865489    -0.763126       1.0  \n",
       "31  MLPClassifier    -0.210931     -0.113191    -0.002871       1.0  \n",
       "32  MLPClassifier    -2.122636     -1.865527    -1.569005       1.0  \n",
       "33  MLPClassifier    -0.821988     -0.485629    -0.002983       1.0  \n",
       "34  MLPClassifier    -0.224688     -0.118700    -0.002665       1.0  \n",
       "35  MLPClassifier    -0.966057     -0.854572    -0.733236       1.0  \n",
       "36  MLPClassifier    -0.227734     -0.121283    -0.002030       1.0  \n",
       "37  MLPClassifier    -0.696346     -0.544574    -0.428521       1.0  \n",
       "38  MLPClassifier    -0.350138     -0.166886    -0.003443       1.0  \n",
       "39  MLPClassifier    -0.671237     -0.444487    -0.225970       1.0  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"../datasets/test.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8b71326-91bc-45ed-88d1-bb28ae55cf95",
   "metadata": {},
   "source": [
    "Ogni riga del dataset contiene quindi:\n",
    "\n",
    "- **dataset_id**: ID univoco per ogni dataset analizzato.\n",
    "- **point**: ogni punto del dataset viene semplicemente enumerato da $0$ a\n",
    "  $N-1$, dove $N$ è il numero totale di punti del dataset.\n",
    "- **class**: classe del punto.\n",
    "- **target**: classe target dell'algoritmo genetico.\n",
    "- **model**: il modello classificatore utilizzato.\n",
    "- **min/mean/max_fitness**: valore minimo, medio e massimo di fitness estratti\n",
    "  dalla hall of fame prodotta ad ogni esecuzione dell'algoritmo genetico.\n",
    "- **accuracy**: calcolata come numero di individui nella hall of fame\n",
    "  classificati nella classe target diviso numero di individui totali presenti\n",
    "  nella hall of fame.\n",
    "\n",
    "Possiamo quindi vedere ogni riga come una singola esecuzione dell'algoritmo\n",
    "genetico su uno specifico punto e su una specifica classe target.\n",
    "\n",
    "Dato che i valori di fitness non sono altro che la distanza di ogni punto\n",
    "sintetico dal punto preso in esame, moltiplicata per $-1$. Possiamo quindi\n",
    "convertire le tre colonne di fitness in valori di distanza rimoltiplicandole\n",
    "per $-1$ di modo da avere valori meglio interpretabili.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8291176a-82b4-4fa2-b89a-9aec43f4e457",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset_id</th>\n",
       "      <th>samples</th>\n",
       "      <th>features</th>\n",
       "      <th>classes</th>\n",
       "      <th>clusters</th>\n",
       "      <th>point</th>\n",
       "      <th>class</th>\n",
       "      <th>target</th>\n",
       "      <th>model</th>\n",
       "      <th>min_distance</th>\n",
       "      <th>mean_distance</th>\n",
       "      <th>max_distance</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>SVC</td>\n",
       "      <td>0.863216</td>\n",
       "      <td>0.693211</td>\n",
       "      <td>0.530128</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>SVC</td>\n",
       "      <td>0.212320</td>\n",
       "      <td>0.111060</td>\n",
       "      <td>0.000843</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>SVC</td>\n",
       "      <td>0.122858</td>\n",
       "      <td>0.060963</td>\n",
       "      <td>0.000577</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>SVC</td>\n",
       "      <td>0.584679</td>\n",
       "      <td>0.517216</td>\n",
       "      <td>0.473684</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>SVC</td>\n",
       "      <td>1.069148</td>\n",
       "      <td>1.007200</td>\n",
       "      <td>0.954585</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>SVC</td>\n",
       "      <td>0.194921</td>\n",
       "      <td>0.104197</td>\n",
       "      <td>0.000167</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>SVC</td>\n",
       "      <td>0.898964</td>\n",
       "      <td>0.827281</td>\n",
       "      <td>0.766880</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>SVC</td>\n",
       "      <td>0.177876</td>\n",
       "      <td>0.095933</td>\n",
       "      <td>0.000479</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>SVC</td>\n",
       "      <td>0.202024</td>\n",
       "      <td>0.107771</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>SVC</td>\n",
       "      <td>1.392031</td>\n",
       "      <td>1.347967</td>\n",
       "      <td>1.314164</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>0.814046</td>\n",
       "      <td>0.643415</td>\n",
       "      <td>0.487079</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>0.211688</td>\n",
       "      <td>0.111412</td>\n",
       "      <td>0.002880</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>0.126069</td>\n",
       "      <td>0.061999</td>\n",
       "      <td>0.000577</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>0.568090</td>\n",
       "      <td>0.500289</td>\n",
       "      <td>0.461785</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>1.041980</td>\n",
       "      <td>0.983040</td>\n",
       "      <td>0.946432</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>0.183290</td>\n",
       "      <td>0.101152</td>\n",
       "      <td>0.000195</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>0.867144</td>\n",
       "      <td>0.792772</td>\n",
       "      <td>0.735197</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>0.192574</td>\n",
       "      <td>0.100331</td>\n",
       "      <td>0.000479</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>0.208884</td>\n",
       "      <td>0.114066</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>1.394919</td>\n",
       "      <td>1.347551</td>\n",
       "      <td>1.304130</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>SVC</td>\n",
       "      <td>1.082284</td>\n",
       "      <td>0.942620</td>\n",
       "      <td>0.841080</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>SVC</td>\n",
       "      <td>0.198747</td>\n",
       "      <td>0.106387</td>\n",
       "      <td>0.000342</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>SVC</td>\n",
       "      <td>2.155123</td>\n",
       "      <td>1.876064</td>\n",
       "      <td>1.604303</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>SVC</td>\n",
       "      <td>0.853050</td>\n",
       "      <td>0.490955</td>\n",
       "      <td>0.002983</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>SVC</td>\n",
       "      <td>0.233730</td>\n",
       "      <td>0.124862</td>\n",
       "      <td>0.002665</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>SVC</td>\n",
       "      <td>0.853220</td>\n",
       "      <td>0.722796</td>\n",
       "      <td>0.595085</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>SVC</td>\n",
       "      <td>0.215328</td>\n",
       "      <td>0.111755</td>\n",
       "      <td>0.002030</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>SVC</td>\n",
       "      <td>0.564927</td>\n",
       "      <td>0.407560</td>\n",
       "      <td>0.291370</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>SVC</td>\n",
       "      <td>0.303950</td>\n",
       "      <td>0.161250</td>\n",
       "      <td>0.000913</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>SVC</td>\n",
       "      <td>0.736125</td>\n",
       "      <td>0.563592</td>\n",
       "      <td>0.383636</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>0.980131</td>\n",
       "      <td>0.865489</td>\n",
       "      <td>0.763126</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>0.210931</td>\n",
       "      <td>0.113191</td>\n",
       "      <td>0.002871</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>2.122636</td>\n",
       "      <td>1.865527</td>\n",
       "      <td>1.569005</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>0.821988</td>\n",
       "      <td>0.485629</td>\n",
       "      <td>0.002983</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>0.224688</td>\n",
       "      <td>0.118700</td>\n",
       "      <td>0.002665</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>0.966057</td>\n",
       "      <td>0.854572</td>\n",
       "      <td>0.733236</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>0.227734</td>\n",
       "      <td>0.121283</td>\n",
       "      <td>0.002030</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>0.696346</td>\n",
       "      <td>0.544574</td>\n",
       "      <td>0.428521</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>0.350138</td>\n",
       "      <td>0.166886</td>\n",
       "      <td>0.003443</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>0.671237</td>\n",
       "      <td>0.444487</td>\n",
       "      <td>0.225970</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    dataset_id  samples  features  classes  clusters  point  class  target  \\\n",
       "0            0        5         2        2         1      0      1       0   \n",
       "1            0        5         2        2         1      0      1       1   \n",
       "2            0        5         2        2         1      1      0       0   \n",
       "3            0        5         2        2         1      1      0       1   \n",
       "4            0        5         2        2         1      2      1       0   \n",
       "5            0        5         2        2         1      2      1       1   \n",
       "6            0        5         2        2         1      3      1       0   \n",
       "7            0        5         2        2         1      3      1       1   \n",
       "8            0        5         2        2         1      4      0       0   \n",
       "9            0        5         2        2         1      4      0       1   \n",
       "10           0        5         2        2         1      0      1       0   \n",
       "11           0        5         2        2         1      0      1       1   \n",
       "12           0        5         2        2         1      1      0       0   \n",
       "13           0        5         2        2         1      1      0       1   \n",
       "14           0        5         2        2         1      2      1       0   \n",
       "15           0        5         2        2         1      2      1       1   \n",
       "16           0        5         2        2         1      3      1       0   \n",
       "17           0        5         2        2         1      3      1       1   \n",
       "18           0        5         2        2         1      4      0       0   \n",
       "19           0        5         2        2         1      4      0       1   \n",
       "20           1        5         2        2         2      0      1       0   \n",
       "21           1        5         2        2         2      0      1       1   \n",
       "22           1        5         2        2         2      1      1       0   \n",
       "23           1        5         2        2         2      1      1       1   \n",
       "24           1        5         2        2         2      2      0       0   \n",
       "25           1        5         2        2         2      2      0       1   \n",
       "26           1        5         2        2         2      3      0       0   \n",
       "27           1        5         2        2         2      3      0       1   \n",
       "28           1        5         2        2         2      4      0       0   \n",
       "29           1        5         2        2         2      4      0       1   \n",
       "30           1        5         2        2         2      0      1       0   \n",
       "31           1        5         2        2         2      0      1       1   \n",
       "32           1        5         2        2         2      1      1       0   \n",
       "33           1        5         2        2         2      1      1       1   \n",
       "34           1        5         2        2         2      2      0       0   \n",
       "35           1        5         2        2         2      2      0       1   \n",
       "36           1        5         2        2         2      3      0       0   \n",
       "37           1        5         2        2         2      3      0       1   \n",
       "38           1        5         2        2         2      4      0       0   \n",
       "39           1        5         2        2         2      4      0       1   \n",
       "\n",
       "            model  min_distance  mean_distance  max_distance  accuracy  \n",
       "0             SVC      0.863216       0.693211      0.530128       1.0  \n",
       "1             SVC      0.212320       0.111060      0.000843       1.0  \n",
       "2             SVC      0.122858       0.060963      0.000577       1.0  \n",
       "3             SVC      0.584679       0.517216      0.473684       1.0  \n",
       "4             SVC      1.069148       1.007200      0.954585       1.0  \n",
       "5             SVC      0.194921       0.104197      0.000167       1.0  \n",
       "6             SVC      0.898964       0.827281      0.766880       1.0  \n",
       "7             SVC      0.177876       0.095933      0.000479       1.0  \n",
       "8             SVC      0.202024       0.107771      0.000027       1.0  \n",
       "9             SVC      1.392031       1.347967      1.314164       1.0  \n",
       "10  MLPClassifier      0.814046       0.643415      0.487079       1.0  \n",
       "11  MLPClassifier      0.211688       0.111412      0.002880       1.0  \n",
       "12  MLPClassifier      0.126069       0.061999      0.000577       1.0  \n",
       "13  MLPClassifier      0.568090       0.500289      0.461785       1.0  \n",
       "14  MLPClassifier      1.041980       0.983040      0.946432       1.0  \n",
       "15  MLPClassifier      0.183290       0.101152      0.000195       1.0  \n",
       "16  MLPClassifier      0.867144       0.792772      0.735197       1.0  \n",
       "17  MLPClassifier      0.192574       0.100331      0.000479       1.0  \n",
       "18  MLPClassifier      0.208884       0.114066      0.000027       1.0  \n",
       "19  MLPClassifier      1.394919       1.347551      1.304130       1.0  \n",
       "20            SVC      1.082284       0.942620      0.841080       1.0  \n",
       "21            SVC      0.198747       0.106387      0.000342       1.0  \n",
       "22            SVC      2.155123       1.876064      1.604303       1.0  \n",
       "23            SVC      0.853050       0.490955      0.002983       1.0  \n",
       "24            SVC      0.233730       0.124862      0.002665       1.0  \n",
       "25            SVC      0.853220       0.722796      0.595085       1.0  \n",
       "26            SVC      0.215328       0.111755      0.002030       1.0  \n",
       "27            SVC      0.564927       0.407560      0.291370       1.0  \n",
       "28            SVC      0.303950       0.161250      0.000913       1.0  \n",
       "29            SVC      0.736125       0.563592      0.383636       1.0  \n",
       "30  MLPClassifier      0.980131       0.865489      0.763126       1.0  \n",
       "31  MLPClassifier      0.210931       0.113191      0.002871       1.0  \n",
       "32  MLPClassifier      2.122636       1.865527      1.569005       1.0  \n",
       "33  MLPClassifier      0.821988       0.485629      0.002983       1.0  \n",
       "34  MLPClassifier      0.224688       0.118700      0.002665       1.0  \n",
       "35  MLPClassifier      0.966057       0.854572      0.733236       1.0  \n",
       "36  MLPClassifier      0.227734       0.121283      0.002030       1.0  \n",
       "37  MLPClassifier      0.696346       0.544574      0.428521       1.0  \n",
       "38  MLPClassifier      0.350138       0.166886      0.003443       1.0  \n",
       "39  MLPClassifier      0.671237       0.444487      0.225970       1.0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[[\"min_fitness\", \"mean_fitness\", \"max_fitness\"]] *= -1.0\n",
    "df = df.rename(columns={\"min_fitness\" : \"min_distance\", \"mean_fitness\": \"mean_distance\", \"max_fitness\": \"max_distance\"})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cdda0d5-0ba4-491d-9cfd-47dd763ac064",
   "metadata": {},
   "source": [
    "## Precisione\n",
    "\n",
    "Come prima analisi possiamo andare a vedere i risultati ottenuti da ogni\n",
    "modello, per ogni dataset in termini di accuracy.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4268e792-246c-4d87-8fb9-be2145aed119",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset_id</th>\n",
       "      <th>model</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>SVC</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>SVC</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   dataset_id          model  mean  std\n",
       "0           0  MLPClassifier   1.0  0.0\n",
       "1           0            SVC   1.0  0.0\n",
       "2           1  MLPClassifier   1.0  0.0\n",
       "3           1            SVC   1.0  0.0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby([\"dataset_id\", \"model\"]).agg([\"mean\", \"std\"])[\"accuracy\"].reset_index()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03d675d9-c112-485c-89cf-109d5f2ccf97",
   "metadata": {},
   "source": [
    "Come possiamo notare abbiamo una media di $1.0$ e una deviazione standard\n",
    "di $0.0$ come sperato. Deduciamo quindi che l'algoritmo genetico abbia prodotto\n",
    "la popolazione sintetica finale sperata.\n",
    "\n",
    "## Fitness\n",
    "\n",
    "Vediamo ora se ci sono differenze signi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f838f007-4b8b-482c-b6fe-5f5580848e51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset_id</th>\n",
       "      <th>model</th>\n",
       "      <th>mean_distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>0.475603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>SVC</td>\n",
       "      <td>0.487280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>0.558034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>SVC</td>\n",
       "      <td>0.550784</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   dataset_id          model  mean_distance\n",
       "0           0  MLPClassifier       0.475603\n",
       "1           0            SVC       0.487280\n",
       "2           1  MLPClassifier       0.558034\n",
       "3           1            SVC       0.550784"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_fitness = df.groupby([\"dataset_id\", \"model\"]).mean()[\"mean_distance\"].reset_index()\n",
    "mean_fitness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3b6bbdd2-ee62-4c88-978f-eb253a739eb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1600x900 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "svc = mean_fitness[mean_fitness[\"model\"] == \"SVC\"]\n",
    "mlp = mean_fitness[mean_fitness[\"model\"] == \"MLPClassifier\"]\n",
    "\n",
    "plt.figure(figsize=(16, 9))\n",
    "plt.xticks(mean_fitness[\"dataset_id\"])\n",
    "plt.xlabel(\"Dataset\")\n",
    "plt.ylabel(\"Mean distance\")\n",
    "\n",
    "plt.bar(x=svc[\"dataset_id\"] - 0.076, height=svc[\"mean_distance\"], width=0.15, label=\"SVC\")\n",
    "plt.bar(x=mlp[\"dataset_id\"] + 0.076, height=mlp[\"mean_distance\"], width=0.15, label=\"MLPClassifier\")\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "@deathbeds/jupyterlab-fonts": {
   "styles": {
    ":root": {
     "--jp-code-font-size": "18px",
     "--jp-content-font-size1": "18px"
    }
   }
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
